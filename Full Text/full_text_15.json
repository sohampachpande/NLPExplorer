[{"_id": "Y99-1002", "full_text": "This paper discusses the relationship between the modifying clause and the modified noun in Japanese. In some cases the closeness between them is weaker than in the prototypical case, whereas in others the modification is actually impossible. Within the framework of Matsumoto [I], who applied Frame Semantics to Japanese clausal noun modification, we analyze what conditions make the modification possible. We propose that the degree of linkage between modifier and modified extends from impossibly distant to acceptably close, where the Relational Frame is evoked. This type of phenomenon can be found in various dimensions: space, time, and the cause-and-effect relation. The degree of extensibility is determined by the world-view of the speaker, the tense/aspect choice in the clause, the aspectual character of the noun, and so on.Noun modification in Japanese has a strong hold on linguists' interest, since it has such a diverse types of expression. The most influential work in the field would be Teramura [2], who sees Japanese clausal noun modification as having a dichotomy between Uti no Kankei (Inner Relationship) and Soto no Kankei (Outer Relationship), depending on whether there is a clause-internal gap which has the same reference as the head noun or not. Matsumoto [1], introducing the Frame Semantics developed by Fillmore [3], analyzes noun-modifying clauses into three types according to which element(s) evoke(s) the frame: the predicate in the modifying clause (Clause Host Type), the modified head noun (Noun Host Type), or both of them (Clause Noun Host Type). These studies, however, have concentrated on sharply classifying the expressions and therefore have not been able to capture the real nature of noun modification. Consider the following examples, where the clause kimi o mituketa modifies a noun: (1) a. [[kimi o mituketa] kooen] you ACC found park `the park in which ( ) found you' b. ?[[kimi o mituketa] matu] you ACC found pine.tree `the pine tree at which ( ) found you' Although the relation holding between the clause and the noun is that of the situation and the location where it occurs (LOCATIVE reading), kooen 'park' is perfectly grammatical in (la), whereas in (lb) matu 'pine tree' sounds awkward. In the latter case, however, there is instead a slight possibility of NOMINATIVE reading 'the pine tree found you.' More interestingly, adding a phrase such as omoide no `full of memory' to the noun makes the pine tree example more acceptable: (2) [[kimi o mituketa] omoide no matu] you ACC found memory GEN pine.tree `the pine tree full of memory at which ( ) found you' An examination of this phenomenon will provide us a helpful key to the essence of modification, the relation between the modifier and the modified. What seems to be most relevant here is the degree of closeness which the two have to each other. What does this \"closeness,\" then, mean in modification, and what are the factors which control it? No other study has previously been successful in explaining noun modification from this viewpoint. The purpose of this paper is to investigate the relationship between the modifying clause and the modified noun in Japanese.' We will start our discussion by making a brief survey of the major studies conducted on clausal noun modification in Japanese. Section 3 will examine Matsumoto's Frame-Semantic analysis [1], upon whose framework this study is based. In the fourth section, the concept of \"extensibility\" will be introduced to treat the phenomenon described above not solely in space but also in other dimensions. The factors in this extensibility will then be analyzed in detail to determine in what way the degree of the extensibility is decided. The final section is a conclusion.As a starting point, we will observe the characteristics of noun-modifying expressions in Japanese, noting parallels with general characteristics the Japanese language. As Okutsu [4] states, to study noun modification means to study the structure of Japanese: in other words, the essential structure of the language is well reflected in the structure and meaning of noun modification. We will then make a brief survey of prior theories, in view of the issue posed in the introduction.Japanese has the following characteristics as Kuno ([5]; [6]) and others point out. Let us observe how these characteristics are reflected in the structure of noun modification, as this will be of great help to our later discussion. First, the head noun comes in the final position: (3) [[sensei kara kiita] hanasi] teacher ABL heard story `the story (which) ( ) heard from the teacher' Second, Japanese is a PRO-drop language and therefore the hearer has to recover the missing argument from the context (see the parentheses in the English gloss above). En this sense, Japanese is more pragmatics-oriented than English, as Matsumoto [1] notes. The third characteristic, even more significant, is that Japanese has no relative pronoun. An examination of example (3) will make clear immediately that no relative pronoun is employed in order to connect the two parts, whereas the gloss demonstrates that in English an ACCUSATIVE relative pronoun would be needed. This fact makes two major types of noun-modifying constructions syntactically the same: the relative clause type and the noun complement type. Observe: (4) [[onnanoko ga koguma no okayu o tabetesimau] \t (tofu) hanasi] 2 girl NOM little.bear GEN porridge ACC finish.eating COMP story `the story in which the girl eats the little bear's porridge' We can find a gap in the relative clause type (3). In the noun complement type (4), on the other hand, there is no such gap and, in Matsumoto's [1] term, the noun \"encapsulates\" the content of the clause. This difference Teramura [2] and others have given considerable attention to.Teramura [2] postulates the dichotomy of Uti no Kankei (Inner Relationship) and Soto no Kankei (Outer Relationship), according to whether a gap exists in the modifying clause or not: (5) a. [[sanma o yaku] otoko] saury (fish) ACC grill man `the man who is grilling a saury' b. [[sanma o yaku] nioi] saury ACC grill smell `the smell of grilling a saury' [2] The Inner Relationship in (5a) is caused by the gap in the clause: otoko is relativized in a NOMINATIVE case. In the Outer Relationship instance (5b), on the other hand, nioi cannot be traced to a gap. It should be noted, however, that his Outer Relationship embraces everything other than gap type cases and therefore fails to capture the meaningful difference between (4) and (5b). That is to say, the referent of the noun nioi does not encapsulate the content of the clause but it rather signifies a by-product, a result of grilling. In contrast to Teramura [2], whose approach is interpretive, Okutsu [4] takes a syntactic viewpoint. He -4- applies an Equi-NP deletion to the Inner Relationship type, which he designates as Dooitu Meisi Rental Syuusyoku (Equi-Noun Modification). The other type is Huka Meisi Rental Syuusyoku (Additive Noun Modification), which is classified into two major types: Dookaku Rental Meisi (Appositive Noun), which is exemplified in (4), and Sootai Meisi (Relative Noun) such as the one below: (6) [[Gakko e iku] mae] ni yuubinkyoku ni yotta school GOAL go before LOC post.office LOC stopped `( ) stopped at the post office before ( ) went to school.' Relative Noun represents a point (or a domain) relative to the reference point signified by the clause. We will come back to this sort of noun modification in later sections. He also postulates a subcategory in the first type of Additive Noun Modification for cases such as (5b): Bubunteki Dookaku Rental Meisi (Quasi- Appositive Noun), for cases in which not the whole content but part of the content (e.g. feeling) is appositive to the referent of the noun. He has thrown a new light on this issue in that he has given an independent status to examples such as (5b). It should be noted here that the Quasi-Appositive Noun has some kind of relativeness in common with the Relative Noun. As has already been pointed out, nioi is a by-product and the result of grilling in (5b). This might well be designated as a cause-and-effect relation: there must be a small distance between them, yet the distance should not be a complete gap but a kind of relationship which connects them to each other. This reminds us of the relation between a reference point and the designatum in Relative Noun cases. This has profound implications, which we will discuss later, especially in section 4.Having examined the major studies and their implications for this present study, we now proceed to the Frame-Semantic analysis by Matsumoto [1] (her series of studies on noun modification are found elsewhere, most recently [7]). Observe the following example, which the previous studies would not have been able to explain: (7) [[yaseru]\t onsen] become.slim hot.spring `the hot spring by soaking in which ( ) become(s) slim' (cited by Matsumoto [1]) The example above does not have any clause-internal gap, nor does the noun onsen 'hot spring' encapsulate the content of the modifying clause yaseru `() become(s) slim.' By setting frames as the main apparatus, her theory defines Japanese as a semantics-/pragmatics-oriented language and succeeds in incorporating these seemingly exceptional examples into a simpler trichotomy. Let us have a brief look at Frame Semantics first, which it is based on.In Frame Semantics, developed by Fillmore [3], the frame is a model which is employed to describe the conceptualization of the real world. 3 A linguistic entity such as verb or noun which can be a nucleus of some concept \"evokes\" a frame, that is to say, a larger context or situation where various roles participate. Here some participants may be in a valency relation (i.e. required), while others may not. Observe, for example, the well-known Commercial Transaction Frame by Fillmore & Atkins [8]: (8) Buyer Seller Goods Money BUY\t Subj\t (from) D-Obj\t (for) SELL\t (to)\t Subj\t D-Obj\t (for) \t (excerpted from [8]) The verbs buy and sell evoke a frame of commercial transaction where the elements Buyer, Seller, Goods, and Money participate. Each of these roles must be given grammatical realization: it is realized in different grammatical status according to the verb chosen and the context. For example, in the BUY case, the Buyer role is required to be realized as a subject; in the SELL case, on the other hand, it is optionally realized as a prepositional phrase to NP. What we should note here is that we can capture those diversified transaction situations in a single frame although they are relevant to several different roles and employ different verbs. Matsumoto [1] uses a pragmatic notion, the \"world-view\" of the speaker, in order to explain examples such as (7) above in a single framework. In Japanese, roles which would be impossible in other languages such as English are often involved in a situation. It is appropriate, therefore, to postulate frames in order to explicate the intuition of Japanese speakers. In the next subsection, we will introduce Matsumoto's Frame-Semantic approach, laying emphasis on the points which will be helpful in our later discussion. 3.2 The Three Types of Noun-Modifying Expressions Compare the following examples, where the verb katta 'bought' is employed: (9) a. [[katta] ringo] bought apple\t 'the apple(s) (which) ( ) bought' b. [[katta] hanasi] bought story\t 'the story that ( ) bought ( )' c. [[katta] kaeri] bought way.home\t 'on (one's) way home after ( ) bought ( )' The relation between the modifying clause and the modified noun, however, is different in each case. According to Matsumoto's framework, the examples in (9a), (9b), and (9c) are classified as Clause Host Type, Noun Host Type, and Clause Noun Host Type, respectively. Let us examine each of them in greater detail and discuss the grounds for this classification. The first one, the Clause Host Type, is the most widely distributed. In this type, the verb (predicate) \"evokes\" a Predicate Frame: in (9a), the verb katta evokes a BUY (BOUGHT) Frame, where the role Goods (here ringo) participates. In order to know if a certain element is a participant in a frame or not, she proposes applying a diagnostic with regard to the verb. Suppose that A says \"Kaimasita4 'bought' and B is interested in the situation where he or she bought something. B employs the interrogative form \"sono N w a ...\" so as to obtain some information from A. Sono 'that' is a demonstrative which refers to something which is in the domain of the second person in a way like \"the thing you have just talked about.\" We can safely say that, therefore, if the form \"sono N w a ...\" is possible, the referent of the noun N can be considered to participate in the BUY (BOUGHT) Frame. (10) A: Kaimasita. `( ) bought ( ).' B1: Sono sinamono wa doo desita ka. that goods TOP how was QP `How were the goods?' B2: Sono mise wa doko desu . that shop TOP where is QP `Where is the shop?' B3:??Sono mooke wa ikura desita ka . that profit TOP how.much was QP `How much was the profit?'\t [1] In the above, the noun-modifying expressions [[katta] sinamono] and [[katta] mise] sound natural, whereas [[katta] mooke] does not. The contrast in the following examples well illustrates that Japanese is a semantics-/pragmatics-oriented language. As we have already observed, there may be a gap in the modifying clause which the hearer must recover either from the context or directly from the modified noun. The noun modification concerning Goods (B 1 in (10)) and Place (B2 in (10)) is possible, respectively: (11) a. [[Donarudo Toranpu ga katta] mise] wa doko. Donald Trump NOM bought shop TOP where `Where is the shop (which) Donald Trump bought?' b. [[Tomotyan ga katta] mise] wa doko. little .Tomo NOM bought shop TOP where `Where is the shop in which little Tomo bought ( )?\"\t [1] What decides which role the noun carries, Matsumoto proposes, is the speaker's \"world-view,\" which tells the hearer that a rich person can afford to buy a shop, while a small child cannot. Second, the Noun Host Type is exemplified in (9b). There the noun hanasi 'story' evokes a Nominal Frame and \"encapsulates\" the content of the modifying clause. Another important characteristic of this type is that there is no such gap in the clause that the Clause Host Type has, which is well illustrated in (4) The third type, the Clause Noun Host Type, is introduced exclusively for this Frame-Semantic approach and has particular significance in this present study. As the name suggests, the predicate in the modifying clause and the noun host each other. In this type, what is denoted by the noun participates in the content of the clause and, at the same time, encapsulates the content. Postulating this type will make a great contribution to our analysis. A careful look at example (9c) clarifies that the relationship between the clause and the noun kaeri 'way home,' and the noun itself, have some relativeness: the situation depicted by the modified noun is posted relative to a reference point, which is instantiated by the modifying clause katta . In connection with the noun, the speaker then places on the time axis the situation which would be related to the reference point as in: (12) Sono meron wa [[katta] kaeri] ni tabetesimatta. the melon TOP bought way.home LOC ate/fmished.eating `0 ate the melon on (one's) way home after ( ) bought it.' and the figure below illustrates this: (13) tabetesimatta Since this composite frame has the function of relating the two situations, Matsumoto [1] designates it as a Relational Frame. In fact, this is reminiscent of the Relative and Quasi-Appositive Nouns assumed by Okutsu [4], which imply some relativeness between two situations. By postulating the Clause Noun Host Type, the theory succeeds in dealing with both of Okutsu's nouns, Relative and Quasi-Appositive. It is this relativeness that we should examine again in the Frame-Semantic analysis. Matsumoto [1] without doubt has made a great leap in the field of Japanese noun modification, incorporating a new aspect of Frame Semantics and the pragmatic notion \"world-view\" into the framework. The trichotomy, particularly the Clause Noun Host Type, will contribute to our understanding significantly; however, the classification is, regrettably, too rigid to capture the fact which we observed in the introduction. In the next section, we will return to the question of the degree of closeness which the modifying clause and the modified noun have to each other.Having examined the Frame-Semantic approach to Japanese noun modification, we are now in a position to extend our discussion and observation into the analysis of marginal examples such as the one in (1b).5 4.1 Extension in Space As a starting point, let us return to the examples in (1), which seem to be of the Clause Host Type: (1) a. [[kimi o mituketa] kooen] you ACC found park `the park in which ( ) found you' b.?[[kimi o mituketa] matu] you ACC found pine.tree `the pine tree at which ( ) found you' Recall that in (lb) matu 'pine tree' sounds awkward and there is a slight possibility of NOMINATIVE reading 'the pine tree found you,' although the relation between the clause and the noun is the same in both examples: the verb mituketa 'found' evokes a Predicate Frame in which the nouns kooen and matu appear respectively. Is matu not qualified as a participant in this frame? For what reason does the difference in acceptability arise? In order to seek for an answer to these questions, let us try other nouns which might refer to places where someone might be found. Consider: (14) *[[kimi o mituketa] kootuuhyoosiki] you ACC found traffic.sign `the traffic sign at which ( ) found you' The combination with kootuuhyoosiki is unacceptable because it is a thing which stands on the road as a traffic guide and is scarcely a place where such a situation occurs. See the following as well: (15) [[kimi o mituketa] ??doozool?Hatikoozoo /basutee] statue Statue.of.Hachiko bus.stop Reference Point katta Relation kaeri Situation iR extension modifier modified It should be noted, however, that the acceptability becomes higher in later examples. Doozoo 'statue' still sounds strange, whereas Hatikoozoo 'Statue of Hachiko' is much better, probably because it can be portrayed as a place where people arrange to meet. In the last example, basutee 'bus stop' is perfectly acceptable, since it is definitely a place where people come to wait for a bus. It follows from the discussion above that a certain kind of spatial extension from a point functions in these examples. Such extension is conducted by the speaker's world-view that people get together around some places while they do not in others. In (la), it is obvious that kooen 'park' has a plenty of space inside. In the same way: (16) [[kimi o mituketa] * zitensyal??kurumal?basultuukinbasu] you ACC found bicycle car\t bus commuter.bus `the bicycle/car/bus/omnibus in/on which ( ) found you' Here, each of the nouns denotes a kind of vehicle. The wider space the speaker feels inside the vehicle, the more acceptable the expression becomes. As for tuukinbasu 'commuter bus,' the speaker feels as if he or she is inside the vehicle, exactly in the same manner as the park example. Let me add that as we saw in (lb), there is an incorrect reading in which the bicycle itself found 'you' (the NOMINATIVE reading). Interestingly enough, this reading becomes more likely as the acceptability of the LOCATIVE reading becomes less in (16). We will come back to this point later on. Recall as well that adding a phrase omoide no 'full of memory' to matu 'pine tree' makes the noun modification more acceptable in (2). We can say with reasonable certainty that the same kind of process is working here: the phrase omoide no helps to extend the domain which matu occupies. The pine tree ceases to be a mere thing any more: it is a place where some situation is likely to occur. This observation is supported by the following fact: (17) [[kimi o mituketa] (omoide no) matu no mae/soba] you ACC found memory GEN pine GEN front/side `the front /side of the pine tree (full of memory) at which ( ) found you' Putting after matu the noun mae 'front' or soba 'side,' which is a Relative Noun in Okutsu's theory [4] and a Relational Noun in Matsumoto's [1], the modification is now perfectly acceptable, evoking a Relational Frame. We are now ready to propose a hypothesis to answer the questions posed in the introduction. To modify a thing means that a certain relation holds between the modifying and the modified. In Clause Host Type, the referent of the noun is one of the participants in the Predicate Frame. However, the examples we have observed here demonstrate that the situation is not so clear-cut. There are, in fact, cases where the linkage between the clause and the noun is somewhat different from the prototypical one: the degree of the distance (in other words, closeness) between the two differs from case to case. As is shown in (15) and (16), it can be too great, in which case the modification is impossible, and it can be near enough, in which case modification is possible. In the latter case, what is denoted by the clause is extended to the point where the Relational Frame is evoked. We should bear in mind that this degree of distance is not a dichotomy but a continuum. Therefore our hypothesis is: Hypothesis: the degree of linkage between the modifying clause and the modified noun extends from impossibly distant to acceptably close. This hypothesis is illustrated in the diagram (18) below, where the reference point is in the middle and the area around it signifies the degree of extension: (18) Extension \t (19) Extensibility The reference point is denoted by the content of the modifying clause, and if the extension is enough, it reaches the point signified by the noun. Let us call this degree of extension \"extensibility.\" It seems -8- reasonable to suppose from what we have observed that extensibility is decided at least by the world-view of the speaker and the relation between the clause and the noun. We will discuss this point in section 5. To make our analysis more precise, we have to admit that the extension can be two-way as is illustrated in (19). Recall that in our 'finding you' examples, the more space the speaker feels around or inside the referent of the noun, the more acceptable the modification becomes: in other words, the extensibility is higher. In such examples, therefore, the extensibility of the noun is stronger. Now that the notion of extensibility has been introduced concerning extension in space, we will extend this hypothesis to other dimensions, i.e. to time, and cause-and-effect relations.Cognitive Linguistics argues that the extension of one meaning into another happens very often in our language use. When we conceptualize the world and put it into a language form, we utilize a more concrete and physical experience or image in order to express a more abstract notion. This concrete conceptual structure which is extended to signify another meaning is called an Image Schema (Johnson [9] and Lakoff [10]; see Yamanashi [11] for an analysis of Japanese). The polysemy of a word is produced by an extension of the Image Schema. This subsection will demonstrate that meanings can be extended from space to time. Consider, for example, the extension of the meaning of the noun mae: (20) Hatikoozoo no mae de\t kimi o\t mituketa. Statue.of.Hachiko GEN front LOC you ACC found `( ) found you in front of the Statue of Hachiko.' In (20) above the meaning of mae is that of space, i.e. 'front.' On the other hand, the mae below signifies a temporal relation: (21) Sensoo no mae ni Hatikoo ga sinda. war GEN before LOC Hachiko NOM died liachiko died before the war.' Now that we have seen that the meaning of mae can be extended from space to time, let us examine whether this observation holds in noun-modifying expressions. Compare these Clause Noun Host Type examples: (22) [[Hatikoo ga syuzin o matu] mae] o hitobito ga toorisugita. Hachiko NOM master ACC wait front LOC people NOM passed.by `In front of Hachiko waiting for his master, people passed by.' (23) [[Hatikoo ga sinu/*sinda] mae] ni syuzin ga sinda . Hachiko NOM die died before LOC master NOM died `Before Hachiko died, his master died.' In (22) the noun mae signifies a spatial relation, while in (23) it is temporal. An interesting point to note here is the difference in the English and Japanese tense/aspect system. In English, the tense is past as in died, since the situation holds in the past. In Japanese, on the other hand, the tense/aspect is non-past by default. The reason is that the noun mae requires a default form inside the modifying clause irrespective of the absolute time when the situation occurs, in order to signify that the situation in the modifying clause happens posterior to the situation outside the clause. Though it is not necessary for the purpose of this paper to discuss the tense/aspect system in Japanese in detail, we will return to this point later on. Recall that the extensibility is relatively high because of the world-view of the speaker in (15), where `in front of is already implied: (24) (=15) ?[[kimi o mituketa] Hatikoozoo] you ACC found Statue.of.Hachiko `the Statue of Hachiko in front of which ( ) found you' If we add a Relational Noun to this, the result is perfectly acceptable: (25) [[kimi o mituketa]\t Hatikoozoo no mae] you ACC found Statue.of.Hachiko GEN front `the front of the Statue of Hachiko where ( ) found you' In a temporal dimension, things are somewhat different. The extensibility of the 'before' reading is very low: (26) [[Hatikoo ga sinda] sensoo] (* in the sense of 'before') Hachiko NOM died war `the war before/during which Hachiko died' The example above forces a simultaneity (i.e. no time lag) between the situation in the clause and the referent of the noun: Hachiko died during the war or marginally, after the war. This might be because the combination of the two does not give us an impression of any relativeness. Since the speaker/hearer processes the sentence from the beginning in order, it will obstruct the flow of information if he or she is forced to re-sequence events at the noun sensoo in cases where there is no marker of priority. We will discuss this point again in the next section. The 'before' reading can be expressed, however, in the Relational Noun: (27) [[Hatikoo ga sinda] sensoo no mae] Hachiko NOM died war GEN before `the time before the war, when Hachiko died' In the next subsection, we will extend the observation of the time lag to an even more abstract dimension.As we have seen in the last subsection, a simultaneity or a slight posteriority is normally necessary between the modifying clause and the modified noun. Since the speaker/hearer interprets the sentence from the beginning, he or she encounters the modifying clause first and then the modified noun in Japanese. Due to this process, the situation in the clause naturally holds at the same time with, or precedes, the situation denoted by the noun; with mae, 'before,' this order is reversed. Unless the head noun explicitly states the priority, therefore, this requirement is in effect. A posteriority time lag is, as we can predict, possible if it is not so big. Consider the following, where the situation in the clause precedes what is denoted by the noun asa 'morning': (28) (?)[[yonago ni\t tomatta]\t asa] Yonago LOC stayed.overnight morning `the next morning when ( ) stayed overnight in Yonago'\t (cited by Teramura [2]) The situation yonago ni tomatta `( ) stayed overnight in Yonago' functions as a reference point and extends to the referent of asa 'morning,' where it evokes a Relational Frame. The extensibility therefore is quite high here. The acceptability of this extension, however, is marginal for some speakers of Japanese; therefore in order to remove the time lag, we can employ yokuasa 'next morning' or kaeri 'way home' (see (12) and (13)) to make a perfect Clause Noun Host Type case: (29) [[yonago ni\t tomatta]\t yokuasalkaeri] Yonago LOC stayed.overnight next.morning way.home `the next morning when ( ) stayed overnight in Yonago' `on (one's) way home after ( ) stayed overnight in Yonago' We can employ yoru 'night' to obtain a Clause Host Type example: (30) [[yonago ni\t tomatta]\t yoru] Yonago LOC stayed.overnight night `the night when ( ) stayed in Yonago' Here the two situations hold contemporaneously. The observation above as well can be extended to a more abstract dimension, i.e. the cause-and-effect relation. As we have discussed over and over again since the beginning of this paper, in some cases, there is a sort of relativeness between modifier and modified. We have made it clear in previous subsections that such relativeness does exist, though not so strongly, in cases where the modified noun does not itself seem to show any relativeness, and this can be explained by degree of extensibility. This is the case in spatial and temporal dimensions, and if there is a temporal relation, in some cases we can safely infer that the same relation possibly holds between cause and effect. In the following example, the relation between the referents of the clause and the noun is that of time, and at the same time, of cause-and-effect: (31) [[yonago ni\t tomatta]\t tuke] Yonago LOC stayed.overnight bill `the bill charged for staying overnight in Yonago' The tuke 'bill' is produced as a consequence of staying overnight in Yonago and the extensibility is quite high here. Shirakawa [12] proposes an analysis by Circumstance Presentation, arguing that the modifying clause presents the circumstance in which the hearer can identify the referent of the modified noun. In (28), in his opinion, the result of staying in Yonago is identified in the asa 'morning' and no time lag exists between the two. He suggests that in (32) below there is no such sequence and judges it as unacceptable: -10- (32) (?) [[amaimono o tabesugita] musiba] (* judged by Shirakawa [12]) sweets ACC ate.too.much rotten.teeth `the rotten teeth caused by eating too much sweets'\t [12] We do not share this view, however. In (32), the time lag does exist, though not surprisingly long. Though Shirakawa [12] insists that a big time lag is felt in (32) while there is no time lag in (28), we would not feel such a big difference, and the extension in (32) is adequately successful, though perhaps not perfectly acceptable. This can be explained by extensibility. If we put an adverb which clearly signifies a past definite time to break the connection, the extensibility will become much lower as in: (33) Wkyonenl??konomae amaimono o tabesugita] musiba]' last.year the.other.day sweets ACC ate.too.much rotten.teeth `the rotten teeth caused by eating too much sweets last year/the other day' The more definite an adverbial is, the less possible extension is. The examples above demonstrate that our hypothesis concerning extensibility holds in cause-and-effect relation as well. This section has hypothesized that extensibility affects noun modification in the dimensions of space and time, and also the cause-and-effect relation. Next we will reinforce this by analyzing what sort of factors and conditions can affect this phenomenon.In this final stage of our discussion, we will look even deeper into the issue of noun modification in Japanese. We have already pointed out some of the factors which may affect the modification in earlier sections. For example, the world-view of the speaker sometimes makes the extensibility higher. In this section, we will add some more factors to our theory and analyze them in greater detail.As a first step, let us suggest an answer to the question in the introduction. In (lb) and the first two of the examples in (16), where the extensibility is lower, the modified noun has a NOMINATIVE reading (34a), although similar examples obviously have a LOCATIVE reading (34b). Consider again: (34) (=(16)) [[kimi o mituketa] * zitensyal??kuruma] you ACC found bicycle car a. 'the bicycle/car which found you' b. 'the bicycle/car in/on which ( ) found you' c. 'the rider/driver of the bicycle/car who ( ) found you' The reason why the NOMINATIVE reading appears in marginal examples such as the above is that the Noun-Host-ness becomes stronger in this extension into a Clause Noun Host Type. In this process, the participants in the clause become less affected by the noun, which this time becomes more encapsulating. The situation therefore can be expressed totally within the clause. The NOMINATIVE reading is provoked now, because in a simplex clause, the NOMINATIVE case is the most likely accessible (Keenan & Comrie [13]). It is the world-view which suppress or promotes this reading: if the speaker considers the bicycle as non-agentive, the reading is untenable, whereas if he or she imagines a rider (see note 6) of the bicycle, the result is acceptable. The same explanation can apply to the following example: (35) [[akatyan ga nemutteiru] okaasan no soba] baby NOM sleeping mother GEN side `the mother's side by which the baby is sleeping'\t [4] If we delete the relational noun soba 'side' from this example, the result is definitely unacceptable, although the referent of the noun denotes a place where the baby is sleeping: (36) *[[akaiyan ga nemutteiru] okaasan] baby NOM sleeping mother `the mother by whom the baby is sleeping' Here okaasan 'mother' is an agentive noun and therefore has an utmost possibility of receiving a NOMINATIVE case. Since akatyan 'baby' already has that case in the clause, the cases clash and therefore the modification is impossible.The next factor is the interaction between the tense/aspect system and the aspectual character inherent in the verb and the noun. It is well known that Japanese does not have a clear distinction between tense and aspect. The default form -u expresses the simultaneity or the posteriority, while the past/perfect form signifies the priority (see Kindaichi [14] etc.). In the following example, where the cause-and-effect relation holds, yaku signifies simultaneity and yaita priority: (37) [[sanma 0 yakulyaita] nioi] saury ACC grill grilled smell `the smell of grilling a saury'\t (cf. (5b)) The default form yaku is normal, because for Japanese people, the smell produced when someone is grilling a saury is appetizing. Since nioi can of course be produced after grilling, the past/perfect form yaita is also possible. The example of nioi is therefore fully extensible. Abe [15] notes that (38) below is unacceptable: (38) *[[ie o tateru] gomi]8 house ACC build trash `the trash which is produced when ( ) build a house' He reduces the difference between (37) and (38) to event-ness. This is supported by Okutsu's observation [4] that nioi 'smell' can be used in a verb construction while gomi 'trash' cannot: (39) Ii nioil*gomi ga suru . good smell refuse NOM feel `I smell something sweet.' (gomi example is unintelligible) [4] In our analysis, however, the example in (38) can be explained by the factors which affect the extensibility. The aspectual character inherent in tateru 'build' is accomplishment, which pays attention to the end point of process. In case of the noun gomi 'trash,' unlike nioi 'smell,' it is produced after some activity has finished: in other words, it is related to the end point. The example below proves that if the end of the process is specified aspectually, the extensibility becomes higher: (40) ?[[ie o tatetaltatetesimatta]\t gomi] house ACC built finished.building trash `the trash which is produced when ( ) has/have built a house' In case of taberu 'eat,' which signifies an activity, this observation is proved more clearly: (41) [[*taberun?tabetal?tabetesimatta] gomi] eat\t ate finished.eating garbage `the garbage which is produced when ( ) eat/ate/has eaten'In section 4.1, we have seen that the expression omoide no 'full of memory' functions as a kind of connector: it takes the content kimi o mituketa () found you' and hands it over to the noun matu 'pine tree' to make the extensibility higher. In the following example as well, putting an adjective siawasena `happy' with the head noun improves the extensibility: (42) [[Namie to kekkonsita] ?seikatulsiawasena seikatu] Namie GOAL married life happy life `the (happy) married life with Namie' Some verbal expressions also trigger this process. The auxiliary verb -sugiru `do to excess,' attached to the verb in the modifying clause, connects the situation (i.e. cause) there to the situation denoted by the noun (i.e. effect). Musiba 'rotten teeth' is supposed to be produced after a certain amount of time, and hutukayoi 'hangover' happens the next morning: (43) [[amaimono o ?? tabetal? tabesugita] musiba] (cf. (32)) sweets ACC ate\t overate rotten.teeth `the rotten teeth caused by eating sweets/too much sweets' (44) [[??nondal?nomisugita] hutukayoi] drank drank.too.much hangover `the hangover caused by drinking too much' The expression -sugiru fills up the time lag and thus promotes the extensibility.The world-view of the speaker plays a significant part in Japanese noun modification, since Japanese is -12- semantics-/pragmatics-oriented. Though this factor has been discussed from time to time in this paper, I would like to emphasize this remarkable feature of Japanese in this final subsection. In the following example, the noun sugi 'cedar' sounds strange; however, when it is changed to ipponsugi, the extensibility becomes quite high: (45) [[kimi to wakareta] ?sugi/ipponsugi] you ABL parted cedar (no equivalent in English) `the cedar at which ( ) parted from you' This is because the world-view of the speaker that ipponsugi is a tall cedar which stands alone on the outskirts of a rural village and performs the role of a milestone, and that the speaker can imagine associating a sad story with the tree. The example below shows that if the speaker can think of the situation, e.g. playing hide-and-seek, the modification is possible: (46) (*)[[kimi o mituketa] densinbasira] you ACC found electric.light.pole `the electric light pole behind which ( ) found you' It is concluded that various factors such as case, tense/aspect system, aspectual character of the noun, connector and world-view can affect extensibility. Since the extension is two-way, i.e. from the modifying clause and from the modified noun, these factors can also function at both sides.This paper has approached to noun modification in Japanese from a new perspective. A new notion \"extensibility\" was introduced in order to explain cases where the linkage between the modifying clause and the modified noun is in some way different from the prototypical one. In the opening section, we examined the traditional views of noun modification and pointed out in what way these studies would contribute to our study. We then proceeded to Matsumoto's Frame-Semantic analysis, whose trichotomy is remarkable especially in that it postulates the Clause Noun Host Type, where the clause and the noun host reciprocally and a Relational Frame is evoked. We incorporated extensibility into her framework in order to adjust the theory to fit the facts more precisely. Our analysis hypothesized that the degree of linkage of the modifying clause and the modified noun extends from impossibly distant to acceptably close, and this hypothesis based on the spatial dimension can also be applied to other dimensions: time and the cause-and-effect relation. The extensibility is decided by various factors such as case, tense/aspect system, aspectual character of the noun, connector, and world-view of the speaker. These factors can affect the extensibility from the side of both the modifying clause and the modified noun. Though we laid great stress on the world-view of the speaker, the definition of world-view itself is quite vague, which drawback Matsumoto shares. However, the value of these studies lies in the argument that the speaker plays a substantial role in choosing language expressions. From this point we will be able to go on to an even more detailed and deeper examinations of modification in general.1. It is far beyond the scope of this paper to cover all the noun-modifying expressions in Japanese. In this paper, we will deal with clause-type noun modification only so as to focus on the questions issued in the introduction. 2. Toiu is a complementizer which introduces a modifying clause of complement clause type in some cases. For detailed discussion, see Masuoka [16] and Watanabe & Hone [17] . 3. A similar notion is introduced in various fields such as linguistics, artificial intelligence, and so on. For example, the notion Schema is employed in Cognitive Linguistics by Langacker [18]. Here we will not pursue the issue but restrict our discussion to Fillmore's framework, which will contribute to our study significantly. 4. Kaimasita is a form which is politer than katta . Interestingly enough, this polite form does not normally appear in noun-modifying clauses. 5. The discussion in this section partly overlaps that of Nakayasu [19]. I am deeply indebted to Tokimoto for discussion and examples here. 6. Actually, still more possibe readings exist in this example. If the speaker means a person who was on the bicycle (an extension from the bicycle itself), this espression is possible. 7. The adverb kinoo 'yesterday' should be prevented from occurring not solely because it denotes a -13- definite point in the past, but also because the speaker has a world-view that developing rotten teeth is a very slow process. 8. To make this acceptable, Abe [15] proposes to supplement the verb deru as in: (i)\t [[ie o\t tateru told ni deru] gomi] house ACC build when LOC produce trash `the trash which is produced when ( ) build a house'My sincere thanks go to Shigeru Kushima, Shingo Tokimoto, Carl Mantzel, Hiroaki Utsunomiya and anonymous reviewers of PACLIC 13 for their valuable comments and Yukinori Takubo and Yasukado Watanabe for their generous assistance. 9. REFERENCES [1] Yoshiko Matsumoto, Noun-Modifying Constructions in Japanese: A Frame-Semantic Approach, Amsterdam: John Benjamins, 1997. [2] Hideo Teramura, \"Rental Syuusyoku no Sintakusu to Imi (The Syntax and Semantics of the Noun Modification in Japanese) Nos. 1-4,\" Nihongo Nihonbunka (The Japanese Language and Culture) 4-7, Osaka: Osaka University of Foreign Studies, 1975-1978. [3] Charles Fillmore, \"Topics in Lexical Semantics,\" Current Issues in Linguistic Theory, edited by Peter Cole, Bloomington: Indiana University Press, 1977. [4] Keiichiro Okutsu, Seisei Nihongo Bunpoo Ron: Meisiku no Koozoo (On Generative Japanese Grammar: The Structure of Noun Phrases), Tokyo: Taishukan, 1974. [5] Susumu Kuno, The Structure of Japanese Language, Cambridge, Mass.: The MIT Press, 1973. [6] Susumu Kuno, Nihon Bunpoo Kenkyuu (Study of Japanese Grammar), Tokyo: Taishukan., 1973. [7] Yoshiko Matsumoto, \"Cognitive Framework for Noun-Modifying Constructions in Japanese,\" Proceedings of the 117th Meeting of the Linguistic Society of Japan, 1998. [8] Charles Fillmore and Beryl Atkins, \"Toward a Frame-Based Lexicon: The Semantics of RISK and Its Neighbors,\" Frames, Fields, and Contrasts, edited by Adrienne Lehrer and Eva Feder Kittay, Hillsdale, NJ: Lawrence Erlbaum Associates, 1992. [9] Mark Johnson, The Body in the Mind, Chicago: The University of Chicago Press, 1987. [10] George Lakoff, Women, Fire, and Dangerous Things, Chicago: The University of Chicago Press, 1987. [11] Masaaki Yamanashi, Ninti Bupoo Ron (On Cognitive Grammar), Tokyo: Hituzi Shobo, 1995. [12] Hiroyuki Shirakawa, \"Rental Syuusyoku no Zyookyooteizi Kinoo (Noun-Modifying Clauses for Circumstance Presentation),\" Gengogaku Ronsoo (Discussion on Linguistics) 5, Tsukuba: The University of Tsukuba, 1986. [13] Edward Keenan and Bernard Comrie, \"Noun Phrase Accessibility and Universal Grammar,\" Linguistic Inquiry 8.1, 1977. [14] Haruhiko Kindaichi (ed.), Nihongo Doosi no Asupekuto (Aspect in the Japanese Verb), Tokyo: Mugi Shobo, 1976. [15] Yasuaki Abe, \"Rentai Syuusyoku Setu no Syomondai (Issues in Noun-Modifying Clauses),\" Nihongo no Meisi Syuusyoku Hyoogen (Japanese Noun-Modifying Expressions), edited by Yukinori Takubo, Tokyo: Kuroshio Shuppan, 1994. [16] Takashi Masuoka, Hukubun (Complex Sentences), Tokyo: Kuroshio Shuppan, 1997. [17] Yasukado Watanabe and Kaoru Hone, \"Nihongo Dookakusetu ni Arawareru Hobunkazi no Seikizyooken Saikoo: Hobunkazi `Toiu\"Tono' no Daidoosi Bunseki ni yoru Tooituteki Setumei Sian (A Reexamination of Complementizer Choice in Japanese Appositive Clause Constructions: Towards a Unified Account in Terms of Pro-verbs Iu and da),\" Bulletin of the Edward Sapir Society of Japan 12, 1998. [18] Ronald Langacker, Foundation of Cognitive Grammar Vol. 1: Theoretical Prerequisites, Stanford: Stanford University Press, 1987. [19] Minako NAKAYASU, \"Noun Modification in Japanese: An Explanation by Extensibility,\" Research Bulletin of Kagoshima Women's College 20-2, In Press. -14-", "year": "1999"}, {"_id": "Y99-1003", "full_text": "In this paper, I am going to examine the differences between shei 'who' an shenme 'what' in what Cheng and Huang (1996) refer to as \"bare conditionals\". In such constructions, the conditional and consequent clauses each contain a wh-phrase of the same form and the choice of value for the second wh-phrase varies with the choice of value for the first wh-phrase. This construction is illustrated in (1). (1) Shei xian lai, shei xian chi who first come who first eat `If x comes first, x eats first./Whoever comes first eats first.' I will show that the semantics of shenme 'what' and shei 'who' in such constructions differ with respect to how they refer. When the two wh-phrases in pair in bare conditionals involve shei `who', they must refer to the same person as in (1); but when the wh-phrases in pair involve shenme 'what, they may refer to the same object as in (2) or they may refer to a different object but of the same kind as in (3). (2) Wo zheli de dongxi, ni yao shenme, jiu na shenme I here Gen thing you want what\t then take what `As for my things here, if you want x, then you can take x.' (3) a. Ni dapo shenme, jiu de qu mai shenme (lai pei) you break what then must go buy what to compensate Lit. 'If you break what, then you must go to buy what for compensation.' b. Gege you shenme, wo jiu ye yao you shenme brother have what\t I then also want have what Lit. 'If my brother have what, then I also want to have what.' (2) does not need comments; (3) is worth some more remarks. Imagine a situation where a person breaks a bowl and is asked to compensate for it. In this case, if (3a) is to be true, the person who broke the bowl has to buy a new bowl which is different from the original one for compensation. The meaning of shenme 'what' in (3a) can be compared with the meaning of it in (4). (4) If you break a bowl, then you have to buy it for compensation. Unlike (3a), for (4) to be true, what you have to buy for compensation is the original bowl, which is broken. The contrast between (3a) and (4) is similar to the contrast between (5) and (4), that is, between it and one. (5) If you break a glass, then you have to buy (another) one for compensation. Similar remarks apply to (3b). (3b) can be true in a situation where someone buys a new computer and his younger brother wants to have a computer too. In this situation, the two computers need not be the same one though they could be of the same brand. It thus seems that the shenme- anaphora seen in (3) is more like one-anaphora than it-anaphora. In fact, a large number of bare conditionals involving shenme 'what' are ambiguous between the object-identity reading and the non-object-identity reading. One such example is (6). (6) Ni xiang chi shenme, mama jiu zhu shenme gei ni chi you want eat what mother then cook what for you eat a. 'If you like to eat x, then mother cooks x for you to eat.' b. `If you like to eat something of kind x, then mother will cook something of that kind for you to eat.' The purpose of this paper is to discuss what makes the interpretation of the two wh-phrases different and how this difference can be accounted for. I will show that shei 'who' and shenme `what' actually have different kinds of denotations. While shei 'who' denotes the same type of things as proper names and definite descriptions, shenme 'what' may also denote the same type of things as bare NPs, in additional to proper names and definite descriptions. On the basis of this, I will suggest that in addition to 'thing x', shenme 'what' should also be optionally analyzed as `kind x', parallel to the analysis of bare nouns. This, together with Carlson's (1977) semantics of bare plurals and verb meanings, will account for why shenme-anaphora behaves like English one- anaphora. Apart from the above issue, I will also show that unlike Carlson's approach to bare plurals, Wilkinson's (1996) approach cannot be carried over to Chinese bare conditionals. Finally, I will examine Heim's (1987) proposal of treating what as a disguised expression of 'something of kind x', showing that it cannot be extended to Chinese bare conditionals, either. 2. A Distinction Between Shei 'who' and Shenme 'what' Consider the contrast between (7) and (8). (7) Q: Ni xihuan shei you like who `Who do you like?' A: Wo xihuan Zhangsan/nei-ge nithai I like Zhangsan/that-Cl girl `I like Zhangsan/that girl.' A': *Wo xihuan niihai/jinfa-nillang I like\t girl/golden-hair-girl `I like girls/blondes. (8) Q: Ni xihuan shenme you like what `What do you like?' A: Wo xihuan zhe-ben shu I like this-C1 book `I like this book.' A': Wo xihuan shu I like book `I like books.' The examples in (7) and (8) show that to answer a shei-question, either a proper name or a definite description is an appropriate answer, but a bare NP is not. On the other hand, to answer a shenme-question, one can respond with either a definite description or a bare NP. Shei 'who' and shenme 'what' thus allow different ranges of possible answers. I take this fact to be an indication that the two wh-phrases permit different types of denotations. Shei 'who' may denote something of the same type as proper names or definite descriptions, whereas shenme 'what' may denote something of the same type as proper names, definite descriptions or bare NPs. It should be noticed here that Chinese does not have a plural marker. Therefore bare plurals take the form of bare nouns. I will show that the above distinction between shei 'who' and shenme 'what', coupled with Carlson's semantics of bare plurals to be discussed in the next section, will account for the non-object-identity reading of shenme 'what' in bare-conditionals.It is well-known that bare plurals do not have a constant interpretation, as is illustrated by the examples in (9). (9) a. Dogs are intelligent. b. Dogs are available. c. Dogs are widespread. In (9a), the bare plural dogs seems to have the force of the quantifier most or almost all in that exceptions are admitted. As for (9b), it is appropriate to say that existential force is involved. Finally, none of the above interpretations is appropriate for the bare plural dogs in (9c). Here it seems to refer to a kind of animals. Despite the variety of interpretations seen in bare plurals, Carlson (1977a, 1977b) argues that they are uniformly kind-denoting terms and that the various interpretations do not result from the ambiguity of the bare plurals themselves but can be attributed predictably to some aspect of the predicate/context which they occur with/in. According to Carlson, there are three subdomains of ontological entities in the world: stages, which are \"time-space slices of individuals\", objects, which are the most familiar things like Jimmy Carter or this chair , and kinds, which are individuals themselves such as the species dogs or horses. Since the predicate widespread in (9c) applies exclusively to kinds and the bare plural dogs is a kind-denoting term, (9c) translates as (10). (10) Widespread'(d) (\"d\" in (10) stands for the kind of animals that are dogs.) On the other hand, the predicate intelligent in (9a) basically applies to objects but can be elevated by the \"gnomic\" operator Gn to a kind-level predicate, therefore giving the bare plural generic attribution. The translation of (9b) is (11). (11) Gn(Aintelligene)(d) Finally, stage-level predicates select existential readings. Carlson argues that this is \"the result of applying a predicate which makes a claim about stages to the bare plural\". According to him, a stage-level predicate such as available translates as (12), where R represents a realization relation, xk a kind-level variable and s a stage-level variable.) (12) available: Xxlays[R(y,x) & available'(y)] Thus, when the predicate available is applied to dogs, whose translation is XPvP(d), we get the semantic interpretation (13). (13) XPvP(d)(^Xxk3ys [R(y,x) & available'(y)]) = 3ys[R(y,d) & available'(y)] (after X-reduction) When a stage-level predicate is generalized, it can also give a generic attribution to its subject, giving a generic reading. I omit the details here. This way, Carlson successfully accounts for why bare plurals may have a variety of interpretations, though they are uniformly analyzed as kind- denoting terms. 4. A Semantic Analysis of Bare-conditional Donkey Sentences As mentioned, proper names and definite descriptions denote the type of entity of what Carlson calls objects. Since the denotation of shei 'who' ranges over the same kind of individuals as proper names and definite descriptions, on the assumption that shei 'who' is a proform of proper names and definite descriptions, it must introduce object-level variables in bare conditionals. On the other hand, the denotation of shenme 'what' ranges over the same kind of entities as proper names, definite descriptions and bare nouns. So, on the assumption that shenme 'what' is a proform of proper names, definite descriptions and bare nouns, it should be able to introduce kind-level variables--if Chinese bare NPs denote kinds of things as I will argue later, in addition to object-level variables. I show below that this distinction is the key to unmasking the puzzle why bare-conditional donkey sentences involving shei 'who' are never ambiguous but those involving shenme 'what' can be ambiguous. To begin with, some assumptions are in order. Following Cheng and Huang (1996) and Lin (1996), I assume that wh-phrases in Chinese \"bare conditionals\" introduce restricted free variables that must be bound by some operator around the construction. Also, I assume with Kratzer (1978), Heim (1982) and Kadmon (1987) that if a conditional does not contain an overt operator for the conditional clause to restrict, it can be understood as involving a null necessity operator or a covert adverb of quantification roughly equivalent to generally or always. These null operators can bind the variables introduced by the wh-phrases (Cheng and Huang (1996) and Lin (1996)). Now consider (3) again, repeated below. (3) shei xian lai, shei xian chi who first come who first eat `If x comes first, x eats first.' Since the wh-phrase shei 'who' only introduces an object-level variable, the tripartite structure of (3) is (14), where the universal quantifier represents the implicit adverb of quantification of the bare conditional. (14) Vxo [x is a person and xo comes first] [xo is a person and xo eats first] In (14), since the object-level variable x in the restriction and the one in the nuclear scope are semantically bound by the same implicit universal operator, the value for the two variables is always the same. This explains why the two shei's 'who' in (3) must refer to the same individual. Next, let us consider the case of shenme 'what'. As discussed previously, (8) contrasts with (3) in that the two wh-phrases do not refer to the same object, though they involve a higher level identity. (8) Ni dapo shenme, jiu de qu mai shenme (lai pei) you break what then must go buy what to compensate Tit. If you break what, then you have to buy what for compensation.' (8) has a reading equivalent to something like \"If you break a glass, then you have to go to buy a glass for compensation. If you break a bowl, then you have to go to buy a bowl for compensation. If you break a plate, then you have to go to buy a plate for compensation. And so on and so forth\". In other words, for any value assignment which makes the conditional clause in (8) true, it should also make the consequent clause true and this value must be a kind of things. Moreover, given a kind of things as the value for the wh-phrase shenme 'what', that kind of things is understood as being existentially quantified. Imagine a glass-breaking event. If a glass-breaking event takes place, one certainly does not break all the glasses that constitute the kind of things called glass but some glass(es) that realize(s) that kind. Likewise, one can only buy some objects realizing the kind of things called glass but not the kind itself, because the verb mai 'buy' does not apply to a kind-level entity. One can paraphrase this semantic intuition of (8) as follows. (15) For any kind of thing x, if there exists some object y of kind x that you break, then there must exist some object z of kind x such that you go to buy z for compensation. If this paraphrase of (8) is correct, this means that the two shenme's in (8) must simultaneously involve existential quantification over object-level variables and universal quantification over kind-level variables. How is this double quantification possible? Doesn't the wh-phrase shenme `what' introduce a single variable under Kamp's (1981) or Heim's (1982) analysis of indefinites? A solution to the above puzzle suggests itself when one recalls Carlson's (1977) semantics of bare plurals and verb meanings. Recall that the denotation of shenme 'what' ranges over bare nouns, proper names and definite descriptions. Thus, on the assumption that shenme 'what' is a proform of bare nouns, it is reasonable to assume that shenme 'what' can have a denotation similar to that of bare nouns, in addition to that of proper names and definite descriptions. Now suppose that one analyzes Chinese bare nouns the same way as Carlson (1977) analyzes English bare plurals; that is, bare nouns are names of kinds of things. In fact, Krifka (1995) has argued for this position for Chinese bare nouns. Then, it is reasonable to say that the indefinite wh-phrase shenme 'what' can introduce either a kind-level variable or an object-level variable. If the wh-phrase shenme in (8) introduces a kind-level variable, then coupled with Carlson's style of verb meanings for dapo `break' and mai 'buy', (16) will be the logical form of (8). (16) Vxk [3ws[R(w,xk) & break'(you',w)]][3zs[R(z,xk) & go-to-buy-for-compensation'(you',z)]] (16) claims that for all x, x a kind of things, if you break some stage of x, then you have to go to buy some stage of x. The translation (16) captures the intuition that both wh-phrases in (8) have existential force. They have existential force because verbs like dapo 'break' and mai 'buy' have existential quantification over stage-level variables as part of their meaning when their object is a kind (as in Carlson's analysis of available in (12).) The non-object-identity reading of (8) is therefore explained, because each stage variable is bound by an independent existential quantifier introduced by the verb meaning. Moreover, since stages of a kind may be different, the stage of some kind of things that you break and the stage that you buy for compensation need not be the same. Apart from the stage-level variables bound by the existential quantifier, the logical form of (16) also contains kind-level variables. These variables are those introduced by the two shenme 's `what' and are bound by the implicit universal operator of the conditional. It is the binding of the kind-level variables by the implicit universal operator that is responsible for the intuition that the two shenme's in (8) involve a higher level identity though they do not denote the same object- level individual. We thus account for why the wh-phrase shenme 'what' in (8) seems to involve double quantification and why shenme-anaphora in this case is more like one-anaphora than it- anaphora. The above approach also accounts for why (13) is ambiguous. (6) Ni xiang chi shenme, mama jiu zhu shenme gei ni chi you want eat what mother then cook what to you eat a. 'If you like to eat x, then mother will cook x for you to eat.' b. 'If you like to eat something of kind x, then mother will cook something of that kind for you to eat.' The ambiguity of (6) arises simply because the wh-phrase shenme 'what' can introduce an object- level variable as well as a kind-level variable. If an object-level variable is introduced by the two wh-phrases in (6), they will semantically refer to the same individual; on the other hand, if kind- level variables are introduced, the two wh-phrases only refer to the same kinds of things, but not the same objects.As discussed above, Carlson has uniformly analyzed bare plurals as kind-denoting terms and treated existential readings as a result of verbs applying to stages. However, this analysis has been attacked by Wilkinson (1991), who tries to eliminate stages from Carlson's ontology of things. In this section, based on the result in section 4, I will show that Carlson's existential quantification over stages is independently needed, at least, in Chinese bare-conditional donkey sentences. I will first briefly outline Wilkinson's (1991) analysis of bare plurals and then show that her approach fails to account for existential interpretation seen in bare-conditional donkey sentences. Opposing Carlson's stand, Wilkinson (1991) has argued that bare plurals are ambiguous between names of kinds and variable interpretations. According to her view, bare plurals are kind-denoting terms when they are subjects of predicates which apply exclusively to kinds such as common, widespread or extinct, but can be analyzed along the lines of Kamp (1981) and Heim (1982) when they are subjects of stage-level or individual-level predicates. Thus, unlike Carlson's analysis which would translate (17) and (18) as (19) and (20), respectively, she would translate the same sentences as something like (21) and (22). (17) Fireman are available. (stage-level, existential reading) (18) Fireman are altruistic. (individual-level, generic reading) (19) axs[R(x, & available'(x)] (20) Gn(Aaltruistic')(0 (21) 3x[fireman'(x) & available'(x)] (22) Genx[fireman'(x)][altruistic'(x)] On Wilkinson's analysis, the existential reading of (17) arises because the individual variables introduced by the bare plural are bound by the existential closure operator (See Heim (1982), Diesing (1990,1992)). On the basis of this analysis, Wilkinson argues that existential quantification over stages is not necessary. She also argues that Carlson's habitual sentences have an alternative explanation along the lines of Stump (1985) and hence the use of stages can be eliminated in those cases. Since habitual sentences are not the concern of this paper, I will not go into the detail. On the other hand, Wilkinson attributes the generic reading of (18) to the fact that the sentence structure contains a generic operator. It is this generic operator that binds the variable introduced by the bare plural. She proposes that the generic operator is something like an adverb of quantification such as generally or typically. Despite Wilkinson's attack on Carlson's analysis, I think that Carlson's account for existential readings of bare plurals in terms of stages and verb meanings is needed in the theory of grammar. Let us consider (8) again. (8) Ni dapo shenme, jiu de qu mai shenme (lai pei) you break what then must go buy what to compensate `If you break something of kind x, then you have to buy something of kind x (for compensation).' As discussed in the last subsection, the semantics of (8) involves double quantification, namely, a universal quantification over kinds of things and an existential quantification over objects that realize those kinds of things. I have shown that the existential interpretation of the two wh- phrases in (8) is a consequence of applying the meaning of the verbs dapo 'break' and mai 'buy' to NPs denoting kinds. The problem now is: can Wilkinson's (1991) approach to English bare plurals be extended to sentences like (8)? If like my analysis, she also assumes that shenme 'what' is a proform of proper names, definite descriptions and bare nouns, then shenme 'what' under her analysis should be able to denote kind-level as well as object-level variables. Moreover, the distribution of these two kinds of variables should be determined by the predicates which take the variables as arguments. Namely, kind-level variables must be chosen when they are subjects or objects of predicates which apply exclusively to kinds. Elsewhere, object-level variables must be the denotation of the wh-phrases. These assumptions, however, would lead (8) to a nonexistent reading. In (8), since the verb dapo 'break' and mai 'buy' are not among those predicates which apply exclusively to kinds, the two shenme's 'what' must introduce object-level variables rather than kind-level variables. It follows that the object that you break and the object that you buy must be the same one, because both variables are bound by the same universal operator. However, (8) does not have this reading. I should note here that even if the two shenme's in (8) can introduce kind-level variables in violation of Wilkinson's own assumption, the reading thus derived is still not right. On this analysis, the logical form of (8) should be (23) below. (23) Vx k [you break x ][you have to go to buy x k for compensation] k . In (23), the kind-level variable x is bound by the universal quantifier, thus explaining universal quantification over kinds of things. However, the logical form in (23) is inadequate. As noted, one can only break or buy some objects/stages that realize a kind of things but cannot break or buy the kind itself; namely, the wh-phrases in (8) must also be understood as being existentially quantified. But this part of existential meaning is missing in (23). In order to have existential quantification over objects, an object-level variable must appear. Yet no such variable seems available under Wilkinson's approach, because presumably one wh-phrase only introduces one variable at one time. There is no doubt that extra justification is needed if one wants to claim that a single wh-phrase such as shenme 'what' can denote something like 'object x of kind y', i.e., introducing two different variables at one time. Since I know of no evidence that a single indefinite can introduce two different variables at one time, I take (8) to be evidence that Carlson's explanation of existential interpretation of bare plurals in terms of stages and verb meanings is at least supported by Chinese data.My above analysis of the meaning of shenme 'what' in Chinese bare conditionals is closely related to Heim's (1987) analysis of the meaning of English interrogative what in there-insertion constructions. Safir (1985) has reported the judgements of the following examples. (24) Which one of the two men was there ??in the room/* drunk? (25) Which actors were there ??in the roomn*laughing? (26) ?Who was there in the room when you got home? However, Heim (1987) has found that (27) is completely acceptable. (27) What is there in Austin? As is well-known, definite NPs are not allowed to appear after there in there-insertion construction. The above examples thus suggest that which is strong, just like that, whereas what seems to be weak. In order to explain why what is acceptable in a there-insertion construction such as (27), Heim first discusses (28). (28) How many women do you blame? She argues that to properly interpret (28), it must be semantically analyzed or reconstructed as something equivalent to ?you blame x-many women, where x is quantified in by how. Namely, the semantic analysis of how many N-questions involve reconstructing the wh-phrase back to its pre- movement position except for the interrogative operator. Since x-many must qualify as weak by any semantic definition in spite of the definiteness of the variable x, how many N can certainly appear in there-insertion constructions. Heim tries to assimilate the analysis of what to pied-piped wh-phrases such as how many N. She suggests that wh-movement of what can be treated as some sort of pied-piping in disguise, similar to wh-movement of how many N. She proposes that what should be analyzed as though it were `something of what kind'. Therefore, a what-question involves reconstructing back 'something of kind x' to its pre-movement position and only the variable x is bound by the interrogative operator in Comp. Since 'something of kind x' is transparently indefinite, it follows that the trace of what can appear after there in there-insertion constructions. From the above discussion, it seems that my analysis of shenme 'what' in Chinese bare conditionals is somewhat similar to Heim's analysis of English what in there-insertion constructions. In this sense, Chinese bare conditionals can be said to support her analysis of what as involving a kind-level variable. Nevertheless, one crucial difference between Heim's analysis of English what in there-insertion constructions and my analysis of the kind-level shenme in Chinese bare conditionals cannot be ignored. Under my analysis, the semantics of the kind-level shenme 'what' in bare conditionals introduces only a kind-level variable and that is all there is for the meaning of the kind-level shenme 'what'. Existential quantification over objects that realize the kind is ascribed to the verb meaning rather than to the meaning of shenme 'what' itself. But Heim's analysis of English what is different. Apart from introducing a kind-level variable, the meaning of what also incorporates existential quantification over object-level things. Does this difference makes any significant prediction? Substituting Heim's analysis of English what for my analysis of Chinese shenme 'what' will, in most cases, not make any difference for the truth conditions of Chinese bare conditionals. In particular, her analysis of English what can also explain why in examples like (8), the two shenme's need not refer to the same object, though they involve a higher level identity with respect to kinds. They need not be coreferential with respect to object-level things, because each shenme 'what' has its own existential quantifier. But the kind-level variables must be bound by the same implicit universal operator, or vacuous quantification will result (Cheng and Huang (1996)). However, in some cases, Heim's analysis of what seems to fail to assign a bare conditional a proper truth conditions. Consider (29). (29) (Kan) shenme bijiao you jinian\t jiazhi erqie women ye mai-de-qi de, see what more have memorial value and we\t also buy-can-afford women j iu song shenme we\t then give what `If x has more memorial value and we can afford x, then we will give him/her/them x.' Observe that the antecedent clause in (29) involves a coordinate conjunction with a shared-wh- constituent. Namely, the wh-phrase shenme 'what' in the conditional clause is simultaneously the subject of the verb phrase bijiao you jinian jiazhi 'have more value' and the object of the second verb mai-de-qi 'can afford'. What is significant about this fact is that the verb phrase in the first coordinate and the verb in the second coordinate seem to select a different interpretation for the shared wh-phrase. Notice that the interpretation of (29) can be said to be equivalent to the following: If watches have more memorial value and we can afford to buy one, then we willgive a watch; If necklaces have more memorial value and we can afford to buy one, then we will give a necklace; and so on and so forth. In this interpretation, there is no particular watch or necklace that has more value. It is the kind of things called watches or necklaces as a whole that has more value. In other words, the verb phrase bijiao you jinian jiazhi in (29) selects a kind-level subject. In contrast, the verb mai-de-qi 'can afford to buy', does not seem to select a kind-level object, because people only buy (some) objects of a kind of thing, rather than buying the kind itself. ((29) also has another reading in which the wh-phrase refers to an object-level entity. This reading is not relevant to my discussion here.) Above we have seen that the shared wh-phrase shenme 'what' in (29) can be interpreted differently according to the predicate it combines with. However, this cannot be achieved by extending Heim's analysis of what to Chinese shenme 'what'. Although theoretically, Heim's analysis allows shenme 'what' to denote either 'something of kind x' or 'kind x', it seems impossible to say that one and the same wh-phrase can have two different denotations at the same time in one single derivation. Thus, one of the coordinate in (29) will receive no interpretation. In contrast, under my treatment of shenme 'what' as denoting a kind variable, the different interpretations of shenme 'what' can be ascribed to the different semantics of the predicate and the across-the-board transformation.As discussed in the text, the semantics of shenme 'what' in Chinese bare conditionals exhibits a double quantification phenomenon. I have argued that such double quantification can be nicely accounted for if one adopts Carlson's semantics of bare plurals and verb meanings as well as the following two assumptions: (i) shenme 'what' is a proform of bare NPs and hence has the same kind of denotation as bare NPs, and (ii) Chinese bare NPs are names of kinds of things. This analysis of Chinese bare conditionals lends support to Carlson's approach to bare plurals despite Wilkinson's attack on it. I also have shown that an extension of Heim's analysis of what as `something of kind x' to Chinese bare conditionals encounters problems when shenme 'what' is a shared constituent of a predicate which applies to kinds and another predicate which applies to objects.", "year": "1999"}, {"_id": "Y99-1011", "full_text": "In dialogue, speakers are engaged in various types of speech acts other than just those fre- quently encountered such as question, command, promise. The speaker often tries to make sure that his interlocutor has received the information that he is conveying, that his intentions are understood, and that his attitudes toward his interlocutor and the general surrounding environ- ment are clear. Especially in spontaneously spoken discourse or dialogue, these various speech acts are not necessarily expressed in full-fledged well-formed sentences; they are often couched in rather fragmentary, truncated semi-sentences or phrases. In an analoguous manner to Parsons' subatomic event structures, we call these speech acts corresponding to non-full-fledged sentences SUBATOMIC SPEECH ACTS. We show in this paper how these subatomic speech acts are used to form mutual beliefs and to coordinate discourse. We use examples from actual Japanese spoken dialogue to demonstrate that our theory accounts for some of the characteristic phenomena in discourse and assigns correct interpretations and explanations to these phenomena.It is often said that ordinary conversations are full of irregularities. Some say that there is no `grammar' in every day spoken language. In theoretical linguistics, such irregularities in every day conversation has been considered due to various limitations on the performance language use. These phenomena have been regarded as rather peripheral and not a central concern of theoretical linguis- tics, at least that of a grammatical theory. Such an attitude, however, has made it rather difficult to apply the scientific results of theoretical linguistics to the language in actual use. Grammatical theories are particularly vulnerable to. the vulgarity of conversational language because many people speak in incomplete fragmentary sentences. But the fact still remains that people do understand everyday language and that they usually do not find their conversational language anyway more difficult to understand than its written counterpart; on the contrary, it is usually the case that people find the written language spoken to them harder to interpret than spontaneously spoken casual language. So there seems to be a sort of paradox; everyday conversational language seems to lack proper 'grammar' and regularity enjoyed by its written counterpart but is not particularly difficult to understand, while its written counterpart with a proper grammar and regular structure is usually harder, when spoken, to understand. We believe that the paradox is only superficial. The paradox ensues if one assumes that since conversational language does not always follow the rules of its written counterpart, it lacks rules and grammar. If one accepts that conversational language has its own grammar and rules, somewhat different from those of its written counterpart, then there will be no paradox involved. In other words, what we need is a theory of performance, a grammar of language in actual use. We will in this paper explore this aspect of spoken language looking specifically into what con- sititutes its basic unit.Japanese is an agglutinative language with predominantly verb final sentence patterns. It is to be expected, therefore, that Japanese sentence units are rather easy to recognize, and textbooks and written forms of Japanese indeed vindicate such an expectation. -103- [2]: For example, the following would be a typical Japanese sentence in a Japanese grammar book (1) Sensei-ga\t hon-o\t kai-ta Teacher-SUBJ book-OBJ write-PAST `The theacher wrote a book.' Since most of those sentences appearing in a grammar book are of this form, in which verbal forms come at the end, Japanese is typically considered a SOV language. On the other hand, such features as dropping case and conjunctive particles, frequent use of end particles and interjections, and abnormal ordering of words have long been considered signs of `agrammaticism151. These facts seem to corroborate the view that in Japanese grammatical sentence units are well established and rather easy to recognize. When one observes Japanese in actual use, however, one can see that such a view is too simple, because a spontaneously spoken Japanese discourse is full of features which are totally beyond the grasp of grammar books: phrases ending with conjunctions, interjections with verbs attached, unfinished utterances and other disfluencies. These characteristics are often taken as the manifestation of the irregularity and non-systematic nature of spoken language. Although one may decide to ignore these as unimportant performance issues outside the domain of linguistics proper, if one wants sincerely to analyze language in its totality, one cannot avoid meeting these issues. Especially when one wants to recognize 'sentences' in discourse, these characteristics inevitably stand in one's way, destroying the sentential structures expected by grammar. Because of these, from the stand point of the conventional grammar, clarifying such matters as which utterances constitute one sentence and which utterances belong to two different sentence units becomes extremely difficult. If the task of discerning sentence units, the building blocks of discourse, is difficult, the difficulty of discerning discourse structure is enormous.In a coordinated dialogue, the fundamental aspects of the intentions of the participants are conveyed by speech acts conveyed by the utterances in the dialogue. Speech acts, or more properly illocutionary acts, are usually regarded as consisting of an illo- cutionary force and a proposition. In this view, an illocutionary force is comparable to a modality attached to the proposition. If we represent the proposition by P and an illocutionary force by F(.) then an illocutionary act can be represented by F(P)[12]. For example, consider the following sentence: (2) John is a student. If the propositional content of this utterance is represented as: (3) Student(John). When this sentence is uttered with the illocutionary force ASSERT, the entire illocutionary act would be represented as: (4) Student(John). Or, consider another sentence: (5) Open the door. Supplying the unnamed subject of this utterance, one can represent the propositional content of this utterance as: (6) Open(you, the_door). When this sentence is uttered with the illocutionary force COMMAND, the entire illocutionary act may be represented as: -104- (7) ! Open(you,the_door), where ! represents the logical operator corresponding to the illocutionary force COMMAND. When the propositional content of the utterance is rather clear and straightforward, such an understanding of illocutionary forces and speech acts is unproblematic, and most of the work in this area has been based on examples taken from neatly structured, well-formed sentences. But when the propositional content is unclear or when the sentence in question is not quite so neatly constructed, there would be much reconstructing to do to apply this orthodox view of illocutionary acts. Notice that even in the simple case of (5), we assumed that we safely understand the unmentioned subject of the utterance. As has been observed above, an ordinary Japanese dialogue seldom consists of well-formed sen- tences like (2) that corresponds to a proposition. For example, in the following dialogue: (8) Al: eeto, boku-no tukue no-ue-ni desune well my desk\t upon `Well, on my desk' Bl: hai yes `Yes' A2: hon aru-deshou\t yon-satu book there is, isn't there ? four `There are four books, aren't there?' B2: a hai oh yes `Oh, yes' A3: sore-odesune that `Those books' B3: hai yes `uh-hun' A4: tyotto motte kitekuremasuka? a little bring\t can you please? `Can you bring them to me?' B4: hai yes `OK' A's utterances can be interpreted as collectively expressing the speech act essentially the same as the one expressed by the following sentence: (9) boku no tukue no ue ni aru yon sate no hon o motte kite kuremasuka my\t desk existing on four books\t bring me please `Can you bring me the four books on my desk?' As can be seen from these examples, utterances like boku no tukue no ue ni (`on my desk') and sore o (`that one') do not correspond to sentences but phrases or parts of sentences. But these utterances constitute, in some sense, \"units\" of speech. In a way, one can see that in this sense, an actual dialogue is not a static, well-ordered act which only involves a well-formed, so-called grammatical sentence which expresses an illocutionary act corresponding to a whole proposition, but rather a dynamic act in which pieces of utterances that are smaller than what are usually considered sentences are gathered together to convey, as a whole, a spontaneous intention or speech act. It is therefore reasonable to consider a unit of speech smaller than sentences. If a sentence corresponds to a proposition, then these units smaller than sentences would cor- respond to parts of a proposition. One can call these parts of a proposition subatomic proposition. -105- If a stretch of discourse, consisting of several fragmentary utterances, proposes something then the discourse as a whole may be viewed as expressing the same speech act of proposal that would be expressed using some single well-formed sentence. If this single well-formed sentence represents a proposition, then each of the fragmentary utterances that constitute the stretch of discourse would be representing a part of the proposition, a subatomic proposition. And to make the paralell com- plete, each of the subatomic propositions would, with a certain type of, not necessarily illocutionary, force, correspond to a subatomic speech act, which is part of the act of proposal.The term subatomic proposition is inspired by Parson's SUBATOMIC SEMANTICS [11], the framework of semantics that studies entities beneath the level of atomic sentences. Parson's theory is close in spirit to Davidson's event logic [3]. In the theory, the sentence (10) Brutus stabbed Caesar in the back with a knife is interpreted as having the following logical form: (11) (3e)[Stabbing(e)&Subj(e,B)SzObj(e,C)SzIn(e,b)SzWith(e, k)] The logical form says in effect that there is an event of stabbing whose subject is Brutus and whose object is Caesar and whose location is in the back and whose instrument is a knife. Notice that each of Stabbing(e), Subj(e, B), Obj(e,C), In(e, b), With(e, k) can be thought of as a proposition and together they constitute the proposition corresponding to the sentence (10). To the extent that (10) represents an atomic proposition, these propositions are subatomic.. Although Parson's subatomic semantics is concerned with events, and is, in that respect, com- mitted to ontology of subatomic entities, our theory is more representational, in that we do not commit ourselves to the exact nature of the subatomic propositions, whether they are actual entities out there or they are just expedient mechanism to allow proper inference and representation. The exact nature of subatomic entities is not especially crucial to our current concern. The concept of subatomic proposition may be considered related to the traditional grammatical notion of bunsetu, though the latter is specific to Japanese while the former is universal. According to Shinkichi Hashimoto [16] a bunsetsu is \"the shortest unit in a sentence when the sentence as language in actual use is divided into as many parts as possible.\" Although Hashimoto does not mention anything similar to the concept of speech act, his understanding of bunsetsu is intuitively similar to ours. Note, however, bunsetsu is part of an actually uttered sentence, whereas subatomic proposition is what is conveyed by such a unit. Sometimes bunsetsu is regarded as a phonological unit, as an accent phrase [10]. In a sense one might understand a bunsetsu as a means in Japanese to represent a subatomic proposition. Now let us consider applying the theory above to Japanese dialogue and speech acts. For example, consider the following sentence: (12) Tokyo-ni itte kudasai Tokyo-TO go please `Please go to Tokyo' In a Searlean manner, the propositional part of the sentence would be: (13) GO_TO (you , TOKYO) . But regarding this sentence as consisting of its subatomic parts, the whole proposition could be expressed as: (14) (30[TO(TOKYO, e) A GO(you,e)] where TO (TOKYO) and GO (you,e) are subatomic propositions composing the whole proposition. It would be feasible to assign this logical form to a sentence that means corresponds to a propo- sition such as 'You went to Tokyo' or 'You are going to Tokyo', because (14) states that there is actually an event in which 'you' go to Tokyo. But since (12) does not describe an actual state of affairs but a possible state of affairs in the future, (14) is not quite appropriate as the logical form for (12). We propose, instead, that the entity in question is the event-type: -106- (15) felTO(TOKYO,e) A GO(you,e)} where any event of you going to tokyo counts as describing the state of affairs in question. Furthermore, in the Searlean analysis of speech act, the illocutionary act represented by the utterance would be: (16) REQuEsT(GO_TO(you,TOKYO)) while in the subatomic framework, it would become something like: (17) REQuEsT({eITO(TOKYO,e) A GO(you, e)}) Notice that even though the illocutionary force REQUEST has a scope over the whole proposition, the subatomic analysis makes it possible to extract a subatomic proposition (type) of the form, e.g.: (18) {elTO(TOKYO, e)} in which the concept of going to Tokyo is simply represented. With this recourse at hand, we can analyze a series of utterances such as the following: (19) a, anoo, Tokyo ni desune, eeto, itte kuremasuka? \t to Tokyo\t go would you please `Well, would you please go to Tokyo?' Observing that desune and ne can be attached to forms corresponding to subatomic proposi- tions, one can presume that Japanese 'sentences' may be taken as semantically denoting subatomic propositions, and not full propositions. On the other hand, it might be argued that in English and other European languages employ 'sentences' corresponding more closely to full propositions.We have shown that Japanese dialogue can be understood to be based on subatomic propositions, and hence that the basic unit of analysis for Japanese dialogue may be utterances corresponding to subatomic propositions rather than full-fledged sentences corresponding to propositions since the latter is often not obvious in actual Japanese dialogue. We will see in this section how these subatomic propositions are related to illocutionary acts, and how speech acts in dialogue are to be construed. So let us consider applying the theory presented in the last section to the dialogue (8), which is taken from a real conversation. The speaker A's utterance in (8) is made up from four turns, each of which is, in the traditional grammatical sense, not quite well-formed. In our analysis, these turns are understood as representing subatomic propositions. The first turn, which is repeated here as (20), (20) Al: eeto, boku no tukue no ue ni desune \t well my desk\t upon `Well, on my desk' can be interpreted as a speech event in which something, whose identity is unknown yet, on the desk is mentioned. Notice that unlike in the case of Tokyo-ni, this cannot be rendered as {elON(e,my_desk)}, since that something in question that is on the desk is obviously not an event, but rather some object still unspecified. So it is a type of object that is, possibly, on the desk. In other word this speech event is describing an event in which unspecified entity on the desk is mentioned. Let us represent this described proposition, albeit somewhat cumbersomely, as: (21) fej{x1{0N(x, my _desk , e)}} . This in effect says that the utterance in question refers to a subatomic proposition, which is an event type, in which some type of object on my desk is described. The next turn, which is repeated here: (22) A2: hon aru deshou\t yon satu book there is, isn't there ? four `There are four books, aren't there?' in effect says that the object in question was in fact a book, and there are four of them. If we represent the subatomic proposition as: {elbook(b, e)} , it would imply that any one argument pred- icate becomes relational in our analysis. This is not a very satisfactory situation. So instead of writing every event type involving a predicate P as {elP(z , e)} , let us write e P(z), which can be informally read `13(z) in e'. In this notation the representation for the first turn would now become, not (21), but rather: (23) e i\t {xion(x,my_desk)} and that for (the first part of) the second turn would become: (24) e2 1.= {xlbook(x)} and the latter part of the second turn would be: (25) e2\t {zicard(z,4)}. Strictly speaking, there is another element to be noticed. It is the verb aru 'be' in the second turn. We can denote the fact that this verb is used in this turn as an independent subatomic proposition of the form: (26) e 2\t Action(be), though whether 'be' is an action is an issue too problematic for us to go into here. Notice, however, that the 'illocutionary force' of these subatomic propositions is not really that of assertion or claim, but rather that of confimation, as can be seen from the phrase phrase 'isn't there?' The whole point of these turns is to ascertain that the hearer recognizes that there is indeed such an entity, and to construct the mutual understanding that the speaker is talking about that entity. For the sake of clarity, let us write this in the following manner: (27) e 2\t Force(CONFIRM) But this notation is misleading since we do not want to claim that this is also part of subatomic propositions constituting the whole proposition; rather the force is carried by the proposition. But we do not go into this either. In a similar manner, the third turn: (28) A3: sore-o\t desune that-OBJ `Those books' would be rendered as: (29) e3 1-= Obj(dem), where dem is the all-purpose demonstrative, here standing for sore, whose its referent or antecedent is to be resolved from the discourse context. The fourth turn is also rendered as before: (30) A4: tyotto motte kitekuremasuka? a little bring\t can you please? Tan you bring them to me?' where the subatomic proposition is: (31) e4 I= Action(bring) while the illocutionary force is: -108- on(x , my _desk) e21\t {y, z} book(y) car d(z , 4) [x y = Action(be) e41\t {} [x = dem] Action(bring) CONFIRM e l I\t {x} on(x , my _desk) e21\t 1Y, z} book(y) car d(z , 4) [x = y = z] Action(be) REQUEST e31\t {} Obj(dem) e4I\t {} [x = dem] Action(bring) (32) e4\t Force(REQuEsT). One can notice that this series of turns can be broken into two parts, with the two verbs, aru and motte-kite, at each end. We can build a discourse structure representation for that portion of dialogue, converting our subatomic propositions into conditions in Discourse Representation Theory (DRT). The result would be as in the following: The second part of the dialogue, with the third and fourth turns, can also be converted into a discorse structure representation using DRT notation. In a way, one can say that both of these two portions are 'governed' by the two verbs that are related to actions; each of the subatomic propositions constituting the turns contributes to and culminates in the verb at each end. These actions can be taken to represent a sort of unit that somehow corresponds to a speech act: the first corresponding to confirmin and the second to requesting. All told, the utterance of the speaker A would constitute the following speech act: (33) (34) Thus we have indicated that our theory of subatomic proposition is capable of capturing the traditionally irregular aspects of spoken Japanese dialogue and manages to construct a discourse strucutre that is amenable to formal treatment.We have discussed the unit of utterance in spoken Japanese and its relation to dialogue exchange. We have shown that utterances in ordinary spoken Japanese dialogue are not 'well-formed' in the traditional grammatical sense but is governed by different rules. We have proposed one such is that spoken dialogue is often composed of subatomic propositions. We also showed how these subatomic propositions are related to discourse structures and utterance exchanges.The authors would like to thank Dr. Ken'ichiro Ishii, the director of Information Science Laboratory, NTT Basic Research Labs, and Takeshi Kawabata, and other members of Dialogue Understanding Group of NTT Basic Research Labs for their support. REERENCES [1] J. Allwood, J. Nivre, and E. Ahlsen. \"On the semantics and pragmatics of linguistic feedback.\" Technical report, Gothenburg Papaers in Theoretical Linguistics, 64., 1991. [2] J. J. Chew. A transformational analysis of modern colloquial Japanese. Mouton, The Hague, 1973. [3] D. Davidson. Actions and Events. Oxford University Press, Oxford, 1980. [4] K. Dohsaka and A. Shimazu. \"A computational model of incremental utterance production in task-oriented dialogues.\" In Proceedings of the 16th International Conference on Computational Linguistics, 1996. [5] M. Iwata. Noo-to Kotoba(Brain and Language). Kyouritsu Shuppan, Tokyo, 1996. [6] H. Kamp. \"A theory of truth and semantic representation.\" In J. Groenendijk, T. Janssen, and M. Stokhof, editors, Truth, Interpretation and Information, pp. 1-41. Foris, Dordrecht, 1981. M. Kawamori, T. Kawabata, and A. Shimazu. \"Discourse markers in spontaneous dialogue: A corpus based study of Japanese and English.\" In M. Stede, L. Wanner, and E. Hovy, editors, the Proceedings of Coling/ACL 98 Workshop on Discourse Relations and Discourse Markers, pp. 93-99, 1998. [8] M. Kawamori and A. Shimazu. \"The notion of control in discourse.\" TR-IEICE, pp. 31-36, 1996. [9] M. Kawamori, A. Shimazu, and K. Kogure. \"Roles of interjectory responses in spoken dis- course.\" In the Proceedings of the 3rd International Conference on Spoken Language Processing, pp. 955-958, 1994. [10] S. Martin. A Reference Grammar of Japanese. Yale University Press, New Haven, 1975. [11] T. Parsons. Events in the Semantics of English: a Study in Subatomic Semantics. MIT Press, Cambridge, Mass., 1990. [12] J. Searle. Speech Acts. Cambridge University Press, Cambridge, 1969. [13] A. Shimazu, K. Kogure, and M. Nakano. \"Cooperative distributed processing for understanding dialogue\" utterances. In the Proceedings of the 3rd International Conference on Spoken Language Processing, pp. 99-102, 1994. [14] H. Suzuki and S. Tutiya. \"A strictly incremental approach to Japanese grammar.\" In J. Barwise, M. Gawron, G. Plotkin, and S. Tutiya, editors, Situation Theory and Its Applications, volume 2, pp. 517-532. CSLI, Palo Alto, 1991. [15] S. Tutiya, K. Shirai, H. Suzuki, and M. Kawamori. \"In search of semantics of Japanese.\" Gengo, 1-12, 1990. [16] M. Watanabe. Kokugo Bunpouron (Theory of Japanese Grammar). Kasama, Tokyo, 1974. [17] S. Whittaker and P. Stenton. \"Cues and control in expert client dialogues.\" In the Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pp. 123-130, 1988. [7}", "year": "1999"}, {"_id": "Y99-1019", "full_text": "Speech is the most natural means of communication among humans. It is also believed that spoken language processing will play a major role in establishing a universal interface between humans and machines. Most of the existing spoken language systems are rather primitive. For example, speech synthesizers for reading unrestrict text of any language is only producing machine-sounding speech. Automatic speech recognizers are capable of recognizing spoken language from a selective population doing a highly restricted task. In this talk, we present some examples of spoken language translation and dialogue systems and examine the capabilities and limitations of current spoken language technologies. We also discuss technical challenges for language researchers to help realize the vision of natural human-machine communication to allow humans to converse with machines in any language to access information and solve problems.", "year": "1999"}, {"_id": "Y99-1023", "full_text": "Da Jinn Wang, Tsong-Yi Chen and Martha W Evens Department of Computer Science and Applied Mathematics 10 West 31' Street, Room 236 Illinois Institute of Technology, Chicago, IL 60616, U.S.A. EMAIL: {wangdaj, chentso}@harpo.cns.iit.edu, mwe@math.nwu.eduFCIDB (Friendly Chinese Interface for DataBase management systems) can understand users' queries in the Chinese language. It works like a translator that translates Chinese queries into SQL commands. In the translation process, the lexicon of FCIDB plays a key role in both parsing and word segmentation. We designed some questionnaires to collect the frequently occurring words and add them to the public 'lexicon in FCIDB. FCIDB will produce a private lexicon for every new connected database. This paper will focus on the words included in the public lexicon and in the private lexicon. We also discuss the function, the structure, and the contents of the lexicon in FCIDB.A natural language interface helps users communicate with computers in their own natural language. Natural language interfaces are an application of natural language processing. The goal of a natural language interface to database management systems (DBMSs) is to help users get information from a DBMS without knowing about databases or their contents. Some natural language interface systems have actually appeared, e.g., LADDER [3], DATALOG [2], and TELI [1]. Today, some domain-independent English interface systems for database are available as commercial products, e.g., English Wizard. English Wizard was developed by the Linguistic Technology Corp. [4]. It allows you to talk to several database management systems, which support Open DataBase Connectivity (ODBC), in the English language. FMDSIC (Friendly Medical Database System Interface in Chinese) is a domain-dependent interface [6]. A domain-independent Chinese interface system, as far as we know, has not appeared before. FCIDB (Friendly Chinese Interface for DataBase management systems) is a domain-independent interface system. It allows users to communicate with database management systems in Chinese. FCIDB translates Chinese questions into SQL, so that your DBMS receives the SQL it expects. The architecture of FCIDB includes the processing components: Look-Up & Word Segmentation, Parsing, Translating to SQL Commands, and Dialogue; and the information components: Lexicon, -215- Chinese grammar rules, SQL grammar rules, and Mapping Dictionary. Figure 1 shows the architecture of FCIDB. The function of the Look-Up and Word Segmentation component is to look up Chinese character strings in a lexicon and determine the word boundary. At the same time, this component obtains information about words from the lexicon, and sends them to the Parser. The Parser applies a set of Chinese grammar rules and a bottom-up parsing algorithm to parse user queries. The Parser must also choose the proper meaning for a word with multiple meanings. During translation the Parser output is reorganized into a legal SQL command. The legal SQL command will be sent to the Dialogue component. Dialogue sends the SQL command to the DBMS and gets the results back. Dialogue must then decide how to phrase the response to the users. If the result is only one value, then the value is included in a sentence. Otherwise, the result is given to the user in table form. We will focus on the lexicon of FCIDB in this paper. In the following sections, we will talk about the function of the lexicon, the structure of the lexicon, and the contents of the lexicon. Get User Query Look-Up & Word Segmentation Lexicon Parser Chinese Grammar Rules Translating to SQL Commands SQL Grammar Rules Mapping Dictionary Dialogue DBMS Software (e.g., Access, dBASE V BMS -n Display Answer to User Fig. 1: The Architecture of FCIDB. (Double bars identify Knowledge Stores)FCIDB has to recognize every word in the input queries. Our lexicon is a computational dictionary that stores information to help FCIDB understand the meaning of words. FCIDB looks up input query words in the lexicon to retrieve knowledge about those words. The main function of lexicon is to provide this knowledge of words. The lexicon plays another role in FCIDB to help to implement word segmentation. In the Chinese language, there are no spaces between the words, so we must determine the word boundaries before other natural language processing steps can be taken. The Chinese/ word segmentation process has been the subject of much intensive research for the past decade. These approaches can be classified into two main groups: 1) the dictionary-based approaches, 2) the statistical approaches [5]. The dictionary-based approaches require a dictionary. They look up character strings in a dictionary and find all words that have the same character sequence as the input sentence. Generally, several different word segmentation strings may be obtained from a Chinese sentence. The maximum- matching (or longest matching) algorithm is often used to select the word sequence that contains the longest words. The dictionary-based approach is applicable to make use for a natural language interface. To implement the longest matching algorithm, words in the lexicon of FCIDB are arranged in descending order.The lexicon in FCIDB includes the following information: the word to match, the word category, the equivalent SQL command word, the equivalent SQL command word type, the synonym, and the related field. Why do we need the equivalent SQL command words? The lexicon of FCIDB represents word meanings as SQL command words, as some other systems use a logical form language as a semantic representation. a. The Word to Match. FCIDB matches each word in the input queries against the words in the lexicon. b. The Word Category. Word categories are nouns, verbs, adjectives, adverbs, pronouns, conjunctions, proper nouns, and so on. c. The Equivalent SQL Command Words. Equivalent SQL commands words are SELECT, COUNT, AND, and so on. d. The Equivalent SQL Command Word Types. Equivalent SQL commands word types are <value>, <table_name>, <conditions>, <operator>, and so on. e. The Synonym. For example, \"*W,\" (discover) and \"-6-T\" (check) have the synonym \"-&:-6:V\" (look into). f. The Related Field. The related field is to record the situation where the word may be used. For example, the word \"VV.\" (a reference to a person on his birthday) may appear in any query to a database that includes the \"birthday\" column.To get high-quality results, FCIDB requires a complete dictionary. It is impossible to suppose that a complete Chinese dictionary will be available, because of the enormous size, new words constantly being produced, too many proper nouns, and so on. And we know \"the larger the lexicon, the slower the search.\" Users can not stand waiting for a result for a long time. To minimize the size of the lexicon, we put only the necessary words that may appear in users' queries into the lexicon. Which words should be put into the lexicon? To find out, we have designed some questionnaires to obtain potential queries in the Chinese language. Using questionnaires to collect queries allowed us to collect a large number of queries in a short time. The disadvantage of questionnaires is that the collected queries do not include all the information available from real conversations. For example, you will not find elliptical queries in the collected queries. In fact, ellipsis often occurs in human dialogue. To make up for this shortcoming, we asked users to work with FCIDB directly once a prototype system was ready. These questionnaires can be divided into two different fields, one field is about school registrar's affairs and the other one is about warehouse affairs. We collected 1405 queries for the school registrar's affairs, and 945 queries for the warehouse affairs. Then, we calculated the frequency of every word in the collected queries. From this experiment, we found some words appearing in the queries to both fields. Actually, these domain-independent words may appear in the queries no matter what the field is. On the other side, some words, which are domain-dependent, appear in the queries to the special fields. FCIDB is a domain-independent interface. It means that FCIDB can work with many different databases. To achieve the goal, the lexicon in FCIDB should include all domain-independent words and all domain-dependent words. We call this lexicon as the public lexicon. When FCIDB is connected to a database, it will automatically produce a private lexicon for the specific database. The private lexicon only includes all domain-independent words and related domain-dependent words. The initial private lexicon is a subset of the public lexicon.No matter what kind of databases we have, domain-independent words are likely to appear in queries. The domain-independent words include: some imperative verbs: e.g., -6g-fij (look for), yin (list) pronouns: e.g., \t (I), 'OE (you) quantifiers: e.g.,\t (all),\t (all) some common verbs: e.g.,\t (please), iriaR (trouble you), \t (is) cardinals and ordinals: e.g., (one),\t (two) prepositions: e.g.,\t (at) interrogative pronouns, adverbs: e.g., 1-1--K-fra (what), aft (who) -218- some most frequently occurring vocabulary: e.g., )clii (greater than), n (of) These domain-independent words are predefined by the system. And every time a new database is built; these words will be added to its private lexicon. Table 1 shows the definition of some domain- independent words in the FCIDB lexicon. The Related Field is not used for domain-independent words. Table 1: Each Row is a Lexical Entry for a Domain-Independent Word in the FCIDB Lexicon. Word Category SQL Word SQL Category Synonym Related Field -6.--ik (look for) VERB SELECT <verb> *1-#fi-J A (please) VERB )c; (greater than) ADJ > <operator> fdn (you) PRONOUN Table 2: Each Row is a Lexical Entry for a Domain-Dependent Word in the Private Lexicon for a School Database Word Category SQL Word SQL Category Synony m Related Field Wt. (student) NOUN STUDENT <table name> _ % (teacher) NOUN TEACHER\t \\\t ,- <table name> _ \" fil (course) NOUN COURSE <table name> _ 0 . \" (take) VERB TAKE <table_name> i T.H El:\t (day of birth) NOUN STUDENT.S_BIRTHDAY <column_names> 41\t * (Dept. of Literature) PROPER NOUN STUDENT.S_DEPT=' 141 *' <conditions> T,\t d \\\t rit, (person's name) PROPER NOUN STUDENT.S_NAME='IPJ\\ wit <conditions> B87160045 PROPER NOUN STUDENT.SID='B871600 45' <conditions> FRI\t 'Ff. (classmate) NOUN -,\t t. (student) ,-\t t (student) t. H (birthday) _ NOUN EXTRACT(MONTH FROM\t { iT t_ H \" }), EXTRACT(DAY\t FROM {fflt_FI \"}) <column_names> IT t. H ill\t (the day\t of birth) -219-When FCIDB is connected with a database management system, the words related to the database should be added to the private lexicon. We classified the domain-dependent words as data dictionary words, proper nouns, special field words, and user defined words. In the public lexicon, FCIDB has predefined the category and synonym for every frequently occurring domain-dependent word. The equivalent SQL command words for every Chinese word needs to ask database administrator to help to define them. Table 2 shows the definition of some domain-dependent words in the private lexicon for a school database. The following subsections will talk about every kind of domain-dependent word more detail. 4.2.1 Data Dictionary FCIDB is a domain-independent interface. It can work with many databases. FCIDB must ask the database administrator to provide Chinese words for every type of information in the data dictionary. These Chinese words represent names of columns and the relationships between tables and between tables and columns in the database. Of course, these Chinese words should be included in the private lexicon. For example, in Table 2, the words iTt_ (student), :g-0 (teacher), \t fl (course), (take), and fflt_ H E (the day of birth) are data dictionary words. 4.2.2 Proper Nouns in Database Proper nouns in databases include personal names, company names, id numbers, and so on. Usually, lexicons do not include proper nouns, because there are too many combinations to include all of them. Some lexicons use the pattern to represent some of proper nouns, for example, Ballard [1] represents the office number with \"(office ((digit 1) (letter 1) (hyphen 1) (digit 3)) ((digit 1) (letter 1) (hyphen 1) (digit 3) (letter 1))).\" From our collected queries, we find the proper nouns appearing in queries that also appear in the database. We append those proper nouns appearing in database to the private lexicon. This makes word segmentation easier. In Table 2, the words 12[1 * (Dept. of Literature), IK/jNgt, (person's name), and B87160045 are proper nouns. 4.2.3 Special Field Words In addition to data dictionary words and proper nouns, FCIDB also predefines some frequently occurring domain-dependent words. We call these words \"special field words.\" From our experiment, --g-N (teacher) can be a title or a person. It will appear in the queries to the databases about school affairs. The Chinese wordy (goods) will appear in the queries to the business databases. If FCIDB works with a school database as an interface, then the word 1 J (goods) does not need to be added to the private lexicon. FCIDB has predefined the category, synonym, and related field for every special field word. It is -220- very difficult to predefine the equivalent SQL command words for every special field word, because FCIDB can not anticipate the names of columns in databases. We have to ask the database administrator to provide Chinese synonyms for all attributes in a new database. Sometimes synonyms for SQL command words are database dependent as well. FCIDB has defined the equivalent SQL commands for some special field words in a dynamic form. For example, in Table 2, we find the SQL command word of t. 19 (birthday) is \"EXTRACT (MONTH, {IT4.E1 }), EXTRACT (DAY, {Wt. H , })\". Here { H ,E (day of birth). Here, { is a dynamic representation. We know that 4 H (birthday) is related with ft H (day of birth). If ffit H, (day of birth) is used for defining a column of table in a database, then t H (birthday) will be added to the private lexicon for the database. At the same time, the dynamic representation, liTit.H , }, will be replaced with the name of the column. For example, ffit. H ) (day of birth) is defined as a column name \"birth\", then the definition of t_ H (birthday) will be modified as \"EXTRACT (MONTH, birth), EXTRACT(DAY, birth)\". But anyway, the best solution is to ask database administrator to help to define the equivalent Chinese words in the special field for every related SQL command. 4.2.4 User Defined Words As we mentioned earlier in this paper, it is impossible for a lexicon to include all words. Users can define missing words themselves. If the predefined word in the FCIDB lexicon does not tally with yours, you can also redefine the words by yourself. FCIDB will replace its old definition with the user's new definition. Table 3: Each Row is a Lexical Entry for a User Defined Word in the Private Lexicon for a Warehouse Database. Word Category SQL Word SQL Category Synonym Related Field g ift (specification of a manufactured item) NOUN A GOODS.G_SIZE, GOODS.G COLOR, GOODS .G WEIGHT <coluinn names> 4 *yr, ;.: (a list of items\t which\t are stored\t in\t ware- NOUN GOODS.G_ID, GOODS.G DES, GOODS.G_QTY <column names> house) ly-iciv; (a list of NOUN J 4 M items\t which\t are stored\t in\t ware- house ) : New words are added to the private lexicon, but not to the public lexicon. So, users can give words (even words predefined by FCIDB) different definitions in different databases. For example, \"E i*\" (retired) can be defined by its equivalent SQL command words \"DateDiff(\"yyyy\", [Birthday], SYSDATE)>65\" in the private lexicon for database A; the same word *\" (retired) can be defined \"DateDiff(\"yyyy\", [BIRTHDAY], SYSDATE)>60\" in the private lexicon for database B. The advantage is that users can define every word.A lexicon is the foundation of a natural language interface. The lexicon is essential to word segmentation and query translation. We carried out an experiment to explore the lexicon. We constructed two different databases and designed questionnaires to collect queries. The results helped us to identify which words we needed in the public and private lexicon. We still need to simplify the word definition process to make it easier for users to add terminology and to move from one database to another. Now, the system can be an interface with ACCESS and Visual dBASE. In the future, we hope to port it to other systems.[1] Bruce W. Ballard, \"A Lexical, Syntactic, and Semantic Framework for TELI: a User Customized Natural Language Processor,\" In: Relational Models of the Lexicon, Edited by M. W. Evens, Cambridge University Press, Cambridge, UK, 211236, 1988. [2] Carole D. Hafner and Kurt S. Godden, Design of Natural Language Interfaces: A Case Study; Research Publication GMR-4567, Computer Science Department, General Motors Research Laboratories, 1984. [3] Gary G. Hendrix, Earl D. Sacerdoti, Deniel Sagalowicz, and Jonathan Slocum, \"Developing a Natural Language Interface to Complex Data\"; ACM Transactions on Database Systems, Vol. 3, 105-147, 1978. [4] Linguistic Technology Corp., English Wizard Version 1.0; Acton, MA, in disk, 1995. [5] Jian-Yun Nie, Xiaobo Ren, and Martin Brisebois, \"A Unifying Approach to Segmentation of Chinese and its Application to Text Retrieval\"; Proceedings of R.O.C. Computational Linguistics Conference VIII, 175-190, 1995. [6] Da-Jinn Wang, Tsong-Yi Chen, and Martha Evens, \"Friendly Medical Database System Interface in Chinese\"; Proceedings of MAICS96, Bloomington, IN. http://www.cs.indiana.edu/eventimaics96/Proceedings/Wang/wang.ps, 1996.", "year": "1999"}, {"_id": "Y99-1029", "full_text": "In NLP, the Case frames of a language are very important for a correct syntactic and semantic analysis of the language. The term Case frames is originated from the Case grammar of Fillmore. However, the term may currently refer to the syntactic part of a lexical entry in grammars such as HPSG, LFG, and the like, or in other place it sometimes includes the semantic part, too. To confirm the common deficiency of the recent approaches to the acquisition of Case frames, let us review some of the related works. Chae-Deug Park studied on learning the Case frames of English without any consideration of preparing sufficient simple sentences as training data [7]. Chae-Kwan Song tried to automatically extract sentence patterns and the information of semantic attributes from the corpus manually tagged with parts-of-speech [8]. Tanaka used sentences analyzed by means of a full parser as training data [9]. Most of such researches so far have used the corpus tagged either by hand or by a parser. Experimental studies in a small scale manage to prepare training data manually. Such a manual arrangement, however, always results in a barrier to doing practical researches on the entire language. On the other hand, the use of any full parser, as it is without any additional processing, brings about a contradiction because the training data are obtained from the unreliable parser. Notice that Case frames are the very information for a further reliable syntactic analysis. Furthermore, currently available parsers for Korean are not even as good as those for English. The training data needed to construct the Case frames for the entire Korean verbs are nothing but a large amount of simple sentences. Unfortunately, however ordinary sentences are not in the form of simple sentences but mixed ones. If we might extract only originally simple sentences from a given corpus, hence a corpus of tremendous size would be required, which is not expected to be available in the near future [11]. This implies that we have to extract simple sentences from mixed ones. Concerning this, assuming that the Case structures and argument structures for all Korean verbs are available, Kwang-Jin Kim extracted simple sentences from embedded ones, though the ultimate goal of his study was a machine This research was funded by the Ministry of Information and Communication of Korea under contract 98-86. -269- translation [4]. However, such linguistic information might not be available for practical NLP until sufficient simple sentences are available. Summing up, we do not rely on such unrealistic assumptions in this study. We just use the output of NM- KTS morphological analyzer, whose rate of accuracy is 96% and probability of guessing unregistered words is 0.75, and hence it is comparatively reliable. As already discussed, the use of a full parser results in consistent reflection of the internal algorithm and Case frames of the parser. Therefore, this study proposes a partial parsing algorithm. Also, to increase the accuracy of analysis we exclude sentences that might bring about fallacy in actual analyses. The approach of partial parsing enables a large amount of incompletely (but not incorrect) analyzed sentences to be used for machine learning. This implies that we may adopt a quite different approach from full parsers.In comparison with English, Korean requires a variety of considerations in developing morphological analyzers. So does it in working on extracting simple sentences from mixed sentences. Therefore, we should, first of all, know the information status in current Korean dictionaries and the linguistic features of Korean. A sentence of Korean may be compound, complex or mixed. A compound sentence consists of two or more coordinate clauses. A complex sentence consists of one main clause and one subordinate clause, which is a constituent of the main clause. The subordinate clause has the adverbial, adnominal or nominal functions. By combining compound and complex sentences we get a mixed sentence, which is structurally complex and compound. Adnouns are a non-inflectional word class that modifies the following nominals. Verbs and adjectives can function as adnominals when used in construction with adnominalizer endings. Adnoun clauses are made up of verbal or adjectival sentences with an adnominalizing ending (-(n)un, -ten, or -(u)l). Korean dictionaries clearly show whether a verb is transitive or intransitive, but there is no information about its complements. In other words, they do not include the information on argument structures. Notice that arguments in this study are the participants (but not necessarily minimally) involved in the activity or state expressed by the predicate. In contrast, most of English dictionaries such as Hornby English Dictionary have the information in the form of parts of verb patterns. Currently, manual work for Korean is being done merely on restricted predicates [1,2]. Korean is relatively free to omit and invert the constituents of a sentence, which is a salient syntactic trait compared with English and thus makes it difficult to pick out the governing domain of each predicate. Furthermore, Korean is an S-O-V language, which means that a verb (or adjective) is a sentence final constituent. Other constituents are relatively free in positional ordering. There is of course a preferred ordering of constituents when no one particular constituent is highlighted for focus or contrast in a discourse. This makes the connection of predicates complicated when the omission and inversion are involved together. To elucidate this phenomenon, let us examine the following example. Hereafter, TOP stands for topic marker, OM for objective one, SM for subjective one, QU for quotative one, and ADNZ for adnominalizer. (1) Ku-nun chayk-ul kunye-lo-pwute pata kalochayssta. He-TOP book-OM her-from received intercepted 'He received a book from her and intercepted it.' The first verb pata 'received' takes chaky-ul 'a book' (for referring to a constituent or argument in a Korean sentence, the combination of the nominal and its Case particle will be described like this) and kunye-lo-, pwute 'from her' as its arguments while the second verb kalochayssta 'intercepted' takes only chaky-wri\"\" book' as its argument (see [3] for more detail). In English, the object 'it' cannot generally be omitted. contrast, Korean frequently omits the object as in the above case. Dong-Young Lee proposed an algorithm of deciding which nominal functions as the subject in a sentence, which has multiple embedded clauses and which contains scrambling or pro-drop phenomenon [5]. The algorithm is summarized as follows: If a predicate is found, its subject is the noun to which the subjective -270- Case particle is attached, satisfying the following three conditions: (a) It is on the left side of the predicate. (b) It is closest to the predicate. (c) It was never before corresponded with other predicates. However, if condition (c) cannot be satisfied, the predicate shares the same subject with the predicate closest to the left of it. To prove the algorithm, the study considered sentence (2) containing only quotative clauses. What is significantly problematic in NLP, however, mainly related to sentences containing relative adnoun clauses rather than to sentences such as (2). Examples (3)-(4) illustrate the flaw of the algorithm. (2) Chelhuy-ka Swunok-i Yengsu-ka ku yenghwa-M poassta-lco malhayssessta-ko sayngkakhanta. -SM\t -SM\t -SM the movie-OM seen.had-QU\t said-QU\t thinks 'Chelhuy thinks that Swunok said that Yengsu had seen the movie.' (3) Ayin-i ttena sulphehanu-n ku-lul poassta. sweetheart-SM left sad.feeling-ADNZ him-OM saw 'We saw him feeling sad because his sweetheart had left him.' (4) Chelswu-ka Yenghey-lul ttaylinu-n kes-ul poassta. -SM\t -OM hit-ADNZ fact-OM saw 'Someone saw that Chelswu hit Yenghey.' or 'Chelswu saw that someone hit Yenghey.' With the algorithm applied to sentence (3), the subject of ttena 'left', sulphehanun 'feeling sad', and poassta 'saw' is construed as Ayin-i 'a sweetheart'. Also, a sentence containing a noun clause as in (4) may have two readings. If the subject of ttayli-nun 'hit' were construed as Chelswu, the subject ofpoassta 'saw' would be omitted. On the contrary, if the subject of poassta 'saw' is construed as Chelswu, the subject of ttayli-nun 'hit' would be omitted. As we see in these counterexamples, the present analysis fails to account for the following two facts: One, a subject can appear on the right side of its predicate if the sentence contains an adnoun clause. The other, a subject may usually be omitted in Korean as shown below. (5) Moluntayyo. not.know.say `He/She said that he/she did not know.' In ordinary English sentences, only the elements of an utterance that may be recovered readily from the syntactic structure can be omitted. In Korean, however, there is a zero anaphor as in (5), which is an unmarked discourse reference, whereas the pronominal anaphor is an unmarked one in English. For inversion or scrambling, let's consider sentence (6). With only this syntactic structure it is hard to say whether hakkyo-lo 'to school' is in the governing domain of poassta 'saw' without referring to any semantic information or context. In English, the governing domain is made clear by using the pronoun 'it' when the sentence has a long subject or object phrase, thus making inversion necessary. There is also a case of the inversion for emphasis, although it is not a frequent linguistic phenomenon. (6) Wuli-nun hakkyo-lo Chelswu-ka kanu-n kes-ul poassta. We-TOP school-to\t -SM going-ADNZ fact-OM saw 'We saw that Chelswu was going to school.' Peculiarly, there are no relative pronouns and relative adverbs in Korean. In case of English, the word order itself marks Case (i.e., implicit Case marking) whereas pronouns including relative pronouns explicitly represent Case by declension (i.e., explicit Case marking). Even when the relative pronouns such as 'that' and 'what' are used, the following word can tell whether the relative pronoun is the subject or object of the sentence. The relative adverbs also indicate that the antecedent is an adverb (or complement) implying place, time, cause, and the like. *.* Astonishingly enough, however, the opposite is true in Korean. The Case particle attached to a nominal explicitly marks the nominal as the subject, object, or complement of the sentence. In a complex sentence , containing an adnoun clause, however, the Case particle attached to the postcedent (in contrast to the term `antecedent' of the English) of the adnoun clause disappears, only with the Case particle for the superordinate clauses (or main clauses) left. The Case particle is essential to reconstructing the clause into a complete simple sentence. To give an example, (7) a. Ku-nun ku-ka kongpwu-lul haysste-n hakkyo-lo tomangchyessta. He-TOP he-SM study-OM did-ADNZ school-to ran.away 'He ran away to the school at which he had studied.' b. Ku-nun hakkyo-lo tomangchyessta. He-TOP school-to ran.away 'He ran away to the school.' c. Ku-ka kongpwu-lul hakkyo-eyse hayssta. He-SM study-OM school-at did 'He had studied at the school.' (7a) consists of a superordinate clause (7b) and a subordinate clause (7c). In (7a), the Case particle -eyse `at' of the phrase hakkyo-eyse 'at the school' in the subordinate clause (7c) disappears, while the Case particle -lo 'to' of the phrase hakkyo-lo 'to school' in the superordinate clause (7b) survives. This implies that it is not possible to recover the Case particle eyse 'at' for the noun hakkyo 'school' in the subordinate clause only with the syntactic structure. Never does this phenomenon occur in English. What is required in this case is to pick out the Case through a semantic analysis. Also it is not always easy to decide whether the postcedent is a complement mainly because of the inherent absence of relative adverbs. This means that the adnominalizers of Korean adnoun clauses behave somewhat similar to both the English relative pronouns 'that, which, and who' and relative adverbs 'when, where, how'. Finally, there may be double nominatives (subjects) or accusatives (objects) within a sentence. When an adnoun clause should be separated from the main clause, this phenomenon becomes problematic. For instance, when there are two objective Case particles within a sentence, the syntactic structure cannot give us any clue on whether each of them belongs to a different predicate or they constitute double objectives for the same predicate.To simplify the problems and enhance the accuracy in partial parsing, this study sets up the following fundamental and detailed principles, and puts asides some linguistic phenomena that need to be further clarified in the field of linguistics.W The processing priority, which reflects the degree of difficulty in partial parsing, is based on Table 1. Necessary information is taken from the corpus only by processing complete sentences (i.e., sentences with priority 1-3) in order of priority. After that, for the priority 4, if a certain event occurs over a given frequency, we credit the information. This means that we take a probabilistic approach. Table 1. Processing priority Priority Type of sentences 1 Simple sentence 2 Compound sentences (conjunctive and disjunctive coordination) 3 Complex sentences containing noun clauses, predicative clause, adverb clauses, guotative clauses, long adnoun clauseLong adnoun clauses take -(n)un as an adnominalizing ending and modify the head noun, which takes no part in it and is appositional to the whole clause. Short adnoun clauses take -1 or -n as an adnominalizing ending. There are two types of adnominal modification, depending on the structural relation between the short adnoun clause and the head noun: One, the head noun is a constituent of the adnominal clause. The other, the head noun is not its constituent. To distinguish these two types, -272- the former is called relative adnoun clauses, and the latter a type of appositive clause. Comparing Korean with English, we interpret Korean grammatical phenomena within the paradigm of the English grammar. This is useful for NLP. (I) We exclude all the pragmatic features that are not inherent features of predicates such as occurring double nominatives or accusatives within a sentence. c5 We treat only the constituents to which subjective, objective, and adverbial Case particles are attached. 3.2 Detailed Principles 0 Adnoun clauses are either relative clauses or appositive clauses. A relative clause is an incomplete sentence. Therefore, a subordinate clause should be considered after the predicate of a superordinate clause takes its obligatory arguments. There are many, so called, phrasal particles, including -ey tayhayse 'about', -ey kwanhay 'concerning' and -lul wihay 'for (the sake of)' as in (8). Such English preposition equivalents are treated as a single particle. (8) Ku-nun cenguy-lul wihay ssawessta. He-TOP justice-OM for fought 'He fought for justice.' 0 The information on a complement requirement is obtained from the processing outcome from priority 1 to priority 3 of Table 1. The sentences having predicates whose a complement requirement is not clear are excluded in this step. 0 The sentences containing appositive clauses like (9) are treated as predicative clauses. (9) a. Cohu-n cem-un ku-ka kongpwu-lul cal hanta-nun kesita. good-ADNZ what-TOP he-TOP study-OM well do-ADNZ fact 'What is good is he does well in school.' b. Sasil-un ku-ka sikyey-lul ilhepelyessta. fact-TOP he-TOP watch-OM lost.has 'In fact, he has lost his watch.' In case of an object inverted in a complete or incomplete sentence, it is possible to restore the inversion according as the predicate is intransitive or not. But in case of an inverted complement, it is hard to tell whether the complement belongs to superordinate or subordinate clauses. In this case, it can be decided on the basis of the behaviors of the other sentences containing the predicate. If a single adjective, intransitive verb, or a noun plus the adnoun form of a predicative Case particle is used as a premodifier (i.e., like alymtawun 'beautiful' in (10a), yehaynghanun 'travelling' in (10b), and hakca-in 'which was a scholar' in (10c)), we do not treat it as an adnoun clause because these simple adnoun clauses are not important for the purpose of this study. ( 1 0) a. Wuli-nun alumtawu-n kkoch-ul cohahanta. We-TOP beatuiful-ADNZ flower-OM like 'We like beautiful flowers.' b. Wuli-nun yehaynghanu-n salam-ul poassta. We-TOP travelling-ADNZ man-OM saw 'We saw a travelling man.' c. Hakca-in Socrates-nun pwulhaynghayssta. scholar-ADNZ -TOP unhappy.was 'Socrates, which was a scholar, was unhappy.' If two nouns are combined by wa kwa 'with or and' as in (1 1), the preceding noun and its Case particle are eliminated. (11) a. Chelsu-wa Yenghuy-nun kongpwuhanta. -and\t -TOP studying 'Chelsu and Yenghuy are studying.' b. Chelsu-wa Yenghuy-ka ssawessta. -with\t -SM fought 'Chelsu fought with Yenghuy.' As in (12), the phrase kunye-uy 'her' in which the possessive Case particle '-uy' occurs is excluded because it is not an argument of the predicate. (12) a. Na-nun kunye-uy son-ul capassta. I-TOP she-POSS hand-OM took 'I took her by the hand.' 3.3 Outside of This Study We remove all the constituents to which no Case particle is attached from a sentence except a predicate. For instance, in (13), kwiyepkey 'pretty' and kippese 'for joy' are removed from the sentence for a further processing even if they are virtual arguments, for they are adverbials without any Case particle. As in (14), the sentences containing multiple predicates occurring in succession are excluded because it is difficult to pick out the governing domain of each only in terms of the syntactic structures. Notice that a Korean adjective needs no copula or linking verb to make a sentence well formed. The adjective can function as a predicate by itself. (13) a. Kunye-nun kwiyepkey sayngkyessta. pretty\t looks 'She looks pretty.' b. Ku-nun kippese nalttwiessta. joy-for jumped 'He jumped for joy.' (14) a. Ku-nun entek-ul neme kako issta. hill-OM over go being 'He is going over a hill.' b. Kukes-un talla pwuthe sseke pelyessta.' stick\t bad went 'It stuck and went bad.' The phenomena and approaches mentioned so far do not cover all linguistic phenomena of Korean. In fact, we deliberately disregarded minor or exceptional phenomena because they do not frequently occur in a real corpus and thus do little affect the amount of training data that we can obtain from a given corpus.In partial parsing, ambiguity occurs mostly in the sentences containing relative adnoun clauses. Therefore, we focus on those types of sentences. In this study, incomplete verbs refer to verbs that take complements. Notice that this study considers only the constituents to which adverbial Case particles are attached as a complement. In Table 2 and 3, a superordinate clause is indicated by So and its predicate P0,; a subordinate clause S, and its predicate P. When S I is an adnoun clause, the postcedent of the clause is referred to as M. The searching orientation forward refers to a scan S from left to right. 'backward' is the reverse orientation. To begin with, we analyze sentences in the corpus morphologically by the morphological analyzer. The following shows the general form after a compound sentence is morphologically analyzed. Here, N refers to a nominal plus a Case particle. S = N, N3 N4 P 1 MN5 N6 PO -274- Table 2. Case processing algorithm Case processing(Input: verb of a sentence) 2 3\t if (verb of a sentence == P0) { search start = N I ; search end = N4; 4\t search orientation = forward; } 5\t else { search end = search start; search start = N4; 6\t search orientation = backward; } 7\t if ((verb of a sentence = transitive verb) and (objective was not found)) 8\t Case searching(objective); 9\t else if ((verb of a sentence == incomplete verb) and (adverbial was not found)) 10\t Case searching(adverbial); 11\t else if (subjective was not found) Case searching(subjective); 12 } Then, the splitting results of a sentence can be described as follows: So = N 1 N2 MN4 N6 Po S i = N3 MP : in case of a relative adnoun clause S 1 = N3 P 1\t : otherwise Table 3. Case searching algorithm Case searching(Input: Case type) 2 { 3 for (from search start to search end toward search orientation) { 4 \t mark which sentence it belongs to; 5 \t Case = Searched Case; 6 \t if (Case = Case type) { 7 \t search start = the location which it is found; 8 \t return(OK); 9 \t } 10 11 if ((sentence type\t short adnoun clause) and (M is used ----- --- NO)) 12 Take the Mas the Case; 13 MOE is used =YES; 14 } 15 else if (Case type != objective) 16 return(ERROR); 17 else return(OK); 18 } For simplicity and understandability, we simply explain the algorithm with the exemplar (15) by using the general form. However, notice that our algorithm can adequately treat all the types of sentences mentioned so far as well as sentences (3)-(4) given early as counterexamples. (15) Chelswu-ka kuli-n phwungkyenghwa-ka cenlamhoy-eyse thuksen-ulo ppophyessta. -SM drawn-ADNZ landscape-SM exhibition-in Special.choice-to was.selected `The landscape that Chulsu had drawn was selected to be Special choice in an exhibition.' The result of the morphological analysis of (15) by NM-KTS is: 'Chulsu-ka [subjective] kulin [P I] pwungkyenghwa-ka [M/subjective] cenlamhoy-eyse [adverbial Case] thuksen-ulo [adverbial Case] ppophyessta [Pa' -275- To begin with, mark that M, N5, and N6 between P, and Po belong to So. The Case processing algorithm of Table 2 will be first applied to Po. Next, P l . By marking each position, all 'pwungkyenghwa-ka [ME/subjective/So] cenlamhoy-eyse [adverbial Case/So] thuksen-ulo [adverbial Case/So]' get to belong to So. Here, we do not need to find an objective Case because P0 is an intransitive verb. When we already obtain the information that Po is an incomplete verb as the result of analyzing the sentences of the processing priority 1-3 in Table 1 (the first fundamental principle), we do not have to try to find an adverbial Case because it has already found. The subjective Case also has already found because M here takes a subjective Case particle. For P 1, we try to find an objective Case particle in the direction of 'backward', but we cannot find it. Since M is not yet used by S we can assume that M takes the objective Case. As a result, we get phwungkyenghwa [objective Case/ MIS,]'. We do not need to try to find an adverbial Case because P, is a complete verb (refer to the first fundamental principle). Finally, we find the subjective Case for P, in the direction of 'backward'. The result is 'Chulsu-ka [subjective Case/So]'.A large volume of simple sentences is a valuable resource in NLP. The collection of simple sentences that results from this study is critical to constructing argument structures and Case structures automatically. In addition, it can be used for building training data for a computer to pick out the thematic roles of arguments within a sentence. Also, in measuring the word similarity for words clustering, the rate of accuracy can be significantly enhanced because the distance between words can be calculated within simple sentences. This study did not assume that currently non-existent information and knowledge exist. In other words, we set up the realistic experimental resources. Then we tried to construct the information necessary to develop Case frames extensively. However, the algorithm presented here has passed through a simple test. This means that an extensive test and modification have been left for future work.[1] Hong, Chae-Seong et al. \"The Lexicon of Verbal Syntax in the Modern Korean Language,\" Dusan Dong-A Press, 1996. [2] Kang, Eun-Kug, \"A Study on Korean Sentence Pattern,\" Seokwang Academic Data Press, 1993. [3] Kang, Hyeon-Hwa, \"A Study on the Overlapping Structure of Verb Linking Constructions,\" Ph.D. Dissertation, Department of Korean Language & Literature. Yonsei University, 1995. [4] Kim, Kwang-Jin et al. \"Implementation of the System Dividing Simple Sentences from Embedded Sentence in Korean,\" In Proceedings of Hangul and Korean Language Information Processing (HKIP), 1994. [5] Lee, Dong-Young, \"A Computational Search for a Verb and its Corresponding Subject in the Korean Sentence Containing Embedded Clauses,\" In Proceedings of the Pacific Rim International Conference on AI., Vol. 2, pp. 219-225, 1992. [6] Manning, \"Automatic Acquisition of a Large Subcategorization Dictionary from Corpora,\" In Proceedings of ACL, 1992. [7] Park, Chae-Deug, \"Incremental Probabilistic Learning of Schema and Case Role Assignment,\" Ph.D. Dissertation, Department of Computer Science, Korea Advanced Institute of Science and Technology, 1993. [8] Song, Chae-Kwan, Seong-Ung Hong, and Chan-Kon Park, \"A Study on the Sentence Pattern of the Korean Language for Machine Translation,\" In Proceedings of HKIP, 1996. [9] Tanaka, Hideki, \"Verbal Case Frame Acquisition from a Bilingual Corpus: Gradual Knowledge Acquisition,\" In Proceedings of COLING, 1994. [10] Yang, Dan-Hee and Mansuk Song, \"Extraction of the Training Data for building Case Frames from a Corpus,\" In Proceedings of HKIP, 1998. [11] Yang, Dan-Hee and Mansuk Song, \"Machine Learning and Corpus Building of the Korean Language,\" In Proceedings of the Spring Conference of the Korea Information Science Society, 1998.", "year": "1999"}, {"_id": "Y99-1030", "full_text": "Being able to define accurately and efficiently word correspondences between parallel texts is an issue in corpus-based machine translation. Translation patterns can be extracted very easily if word corre- spondences between pairs of translation sentences are defined. For sub-sentential alignment, a simple consultation of a machine readable dictionary seems to be a very obvious method. However, the presence of unregistered words, and the difference which may be seen in the surface form of words, or after being processed by a lexical analyzer cause problems. In addition, compound words, which often appear in one-to-many or many-to-many word correspondences, are not covered by single word entry-based dictio- naries. The use, not of dictionaries, but of the parallel corpus itself, has been therefore suggested in order to search word correspondences [4, 5, 6]. Sub-sentential alignment methods which have been proposed are based on statistics. The problem with statistical methods is that they are not able to produce reliable results when the corpus size is limited. For unexplored languages whose huge parallel corpus are still not available, these approaches cannot be applied. In addition, correspondences involving multiple tokens have not yet been entirely resolved [4]. Melamed avoids these cases and considers only one-to-one correspondence [5]. On the other hand, although Kitamura' s [6] main goal is not the sub-sentential alignment, but the extraction of translation patterns, possible correspondences between functional words are not considered. It weakens the method since it decreases the number of translation patterns which could be extracted. We have proposed a French-Japanese example-based machine translation which uses word correspondence-included translation examples [1, 2]. As a relatively new field, a huge parallel corpus is not available. Manual construction of translation examples are very time consuming. An automatic method which can efficiently be applied to size-limited corpus is necessary. In this paper, we propose a method for estimating the word correspondences between new pairs of translation sentences by analogy. Similar pairs are selected from a word correspondences-included initial translation examples. Word correspondences between the new pairs are predicted according to the word correspondences between these similar pairs. By doing so, the method can work with size-limited corpus. Besides, it is considered to be able to resolve efficiently correspondences involving multiple tokens, since solution models are given beforehand within the translation examples. For example, if \"voulez - vous\" -277- New translation pair Search for similar pairs Prediction of the word correspondences of the new pair Translation examples Learning process Figure 1: Overview of the method Table 1: Structure of a translation example French Sentence\t vous/PRV avez/ACJ un/DTN cendrier/SBC ?/? Japanese Sentence\t hazzara/6 wa/9 ari/2 masul14 ka/9 ./1 Correspondence Map 2/3 4/1 5/6 PRV: pronoun, DTN: determinant, SBC: common noun, ACJ: verb \"avoir\" 1: punctuation, 2: verb, 6: noun, 9: particle, 14: suffix (would you) and \"itadake masu ka\" appear in a pair of translation sentences, aligning \"voulez\" with \"itadake\", or \"voulez - vous\" with \"itadake\", or else \"voulez - vous\" with 'itadake masu ka\" are all conceivable. Observation of sentence meaning sometimes produces results which differ from statistic results. Besides, results depend on whether only one-to-one correspondences are considered or not. How- ever, if there is a translation example mapping \"voulez - vous\" or its similar phrase \"pouvez - vous\" (could you) with \"itadake masu ka\", that map can be used as a reference to determine the correspondence maps of the new pair. We introduce, in addition, a learning process-based method for constructing gradually the translation examples. Experiments were performed with French-Japanese spoken language texts, but the method is designed for any unexplored language pairs. The overview of the system is immediately presented and detailed step by step in the next. section. Next, the method of the experiments and the results are described, discussed, and at last, few words are given as a conclusion.The flow of the method is presented in figure 1. The system accepts a new translation pair of sentences, searches multiple similar translation pairs among a set of translation examples or corpus, and computes word correspondences of the new sentence pairs, by using these selected similar pairs. If the result is not accurate, manual correction is performed. The new pair is filially appended to the corpus. On the other hand, the system learns success and failure from the results in order not to reiterate the same mistake. Alignment between two huge parallel corpus can be done by repeating the same operation for all pairs of sentences in them. The structure of an entry in the translation examples is presented in table 1 1 . A token is repre- sented with the format \"token/POS (Part Of Speech) tag\". For the tagging operation, INALF' (Institut 'Meaning of the sentence: \"Do you have an ashtray?\" -278- avezlACJ TN joumal/SBC japonais/ADJ?/? avez/AC TN cendrier/SBC ?/? Sentencel vous/PRV Sentence2 vous/PR Exact match POS tag match Figure 2: Partial matching method National de la Langue Francaise) s EBTI program was used for French sentences and CHASEN1.51[7] tagging program for Japanese sentences. INALF has proposed 70 POS tags for the French language. We removed differences between plural and singular, since they make negative contribution to capture simi- larity of two sentences. 48 POS tags are therefore used. 20 of them are punctuations and 3 are particular cases. As for the Japanese language, POS tags are hierarchically classified, and only the highest level consisting of 14 POS tags is considered. Utilization of syntactic analyzers or semantic analyzers might produce a better prediction of word correspondences. However, these tools themselves, are not extremely accurate. On the other hand, recently developed lexical analyzers are nearly perfect and quite available for different languages. Therefore, only POS tags were used during the prediction. Correspondence maps are of the form wp fl, wp f 2, ... I wpjl, wpj2 , ..., where wpf i are word positions in the French sentence, and wpjj word positions in the Japanese sentence. In the example of table 1, \"2/3\" means that the word \"avez\" corresponds to \"ari\". In the same way, \"cendrier\" corresponds to \"haizara\" (ashtray), and \"?\" to During the manual correction word correspondences were deter- mined according to the meaning of both sentences. Consequently, different possibilities were allowed. A token can have no correspondent, as the case of zero pronoun or some Japanese particles like \"wa\", or some French prepositions and articles. It can also have many correspondents, as in the case of \"s' vous plait\" - \"kudasai\" (please). Besides, many tokens may correspond to many tokens, as is the case with \"voulez - vous\" - \"itadake masu ka\" (could you). In multiple tokens-involved correspondences, non-contiguous segments are also allowed, as in the case of \"n' pas\" - \"masen\" (not) of the segment \"n' ai pas\" and \"ari masen\" (do not exist). Restrictions were avoided because they make the method very specific and unable to face different situations. Inversely, a system which can support different kinds of word correspondences is able to run with any restricted and standardized situation.During the matching process, multiple translation sentence pairs which match the new sentence pairs best are selected from the corpus. If two sentences are similar in one language, their translation sentences are not necessarily similar in the other language. Therefore, similarity between segments of sentences is preferred. It is more probable to discover similar pair of translation sentences if only shorter segments are observed. The search of similar segments of sentences or partial-matching processes is performed independently for both languages. For each word of an input sentence, n sentences having a segment matching the segment containing that word are selected. The partial matching algorithm is as follows: 1. For each token of the input sentence, search an exact matching token in the example sentence 2. If found, start a backward and forward comparison from the found exact match (the comparison starts with considering exact match, and continues with POS tag match when exact match expires, and stops when a mismatch is encountered.) An illustration is presented in figure 2 2 . For the token \"avez/ACJ\" of the first sentence, an exact match is at the second position in both sentences. A backward comparison produces one exact match \"vous/PRV-vous/PRV\", and a forward one yields one exact. match \"un/DTN-un/DTN\", which 2 The meanings of the first sentence and of the second sentence are respectively -do you have a japanese newspaper?\" and \"do you have an ashtray?\" -279- fl: vous/PRV avez/ACJ un/DTN journal/SBC japonais/ADJ ?/? f2: vous/PRV avez/ACJ un/DTN cendrier/SBC ?/? z j2: haizara/6 wa/9 ari/2 masu/14 ka/9 ./1 1%414%44%, 444, t4 jl : nihon/6 no/9 shinbun/6 wa/9 ari/2 masu/14 ka/9 ./1 Figure 3: Search of the word correspondence by analogy is followed by one POS tag match \"journal/SBC-cendrier/SBC\". To select the n best matching segments for each token, the following similarity metric is used: SM = a * NE+ NP\t (1) where SM is the similarity metric, NE the number of exact matches and NP the number of POS tag matches. For the sentences of figure 2, there are 3 exact matches and 1 POS tag match. The similarity metric is therefore: SM=a*3+1\t (2) 3.2 Similarity between two pairs of segments To predict the word correspondences between a new pair of sentences, similar pairs are required. The selected similar sentence will be rejected if any similarity cannot be found between its translation sentence and the translation of the source sentence. The above-mentioned partial matching method is performed independently for both languages. Similarity between translation of the selected sentence and the other language-part of the new pair of sentences has not yet been confirmed. The same algorithm is applied again here to verify that similarity. It is important to mention that the number of segments selected, which were declared to be n per token, may change depending on the situation. No segment is selected when any exact match for the token does not exist. Besides, a same similar segment might be selected for different tokens. In other words, n is the maximum. At most 6n similar segments are selected for 6 tokens sentence.NEW TRANSLATION EXAMPLE After having selected the similar pairs of segments, word correspondences between the new pair of sen- tence is predicted. The process is described in figure 3. (f 1, jl) is the new pair of sentences. (f 2, j2) is a selected pair from the translation examples. Correspondences between f2 and j2 are defined beforehand within the translation examples. Correspondences between f 1 (resp. f2) and jl (resp. j2) are deter- mined during the matching process. The main task here is to find all paths starting from an element of f 1 and reaching an element of jl. In this case, there are two paths, which correspond to two word correspondences \"avez/ACJ-ari/2\" and \"journal/SBC-shinbun/6\". Similarity metrics which where computed during the comparison of source sentences and of transla- tion sentences are added. The prediction process starts with the similar pair having the highest value of that sum. Correspondences involving multiple tokens, which are many-to-many or one-to-many links, are considered only when they came from the same similar pair of segments. In other words, if a token has already been involved in a previous correspondence, any following correspondence involving it will be rejected unless the same similar segment was used during their prediction. -280- Total number of translation examples Average length of Japanese sentence Average length of french sentence Average number of word correspondences per sentence 2,600 pairs 7.74 tokens 7.84 tokens 7.27 Table 2: Data for the experiments 5. FEEDBACK LEARNING PROCESS The system is designed to be operated by different users. Sentences from different domains and incorrect sentences may be typed in. Different points of view, as well as mistakes may also appear during the manual correction. The feedback learning process is introduced here to support the above-mentioned situations. Its idea has already been proposed [3]. Each example in the corpus is given a numeric value FP (Feedback Parameter). If the prediction is not correct, the FP of the involved similar example will be decremented by 1. If it is correct, the value will be incremented by 1. The value FP is combined with the similarity metric to determine the examples which will be use to predict word correspondences of subsequent pairs. Two conditions are defined on FP: 1. Decrementation is always applied on FP when the prediction results are not correct. However, incrementation is applied only to FP whose value has not returned to the initial value. This is decided not only to eliminate incorrect translation examples, but also to avoid a possible restriction to particular translation examples having a high value of FP if incrementation is always considered. 2. FP is initialized to 1. The higher its absolute value is, the more the rejection of the example is probable. During the search of the similar pair the following metric is used: NM = SMIabs(FP) \t (3) SM is the similarity metric, and NM the new metric. NM is not a similarity metric but a metric which is used to decide which sentence is better to predict word correspondences of subsequent pair of sentences.The corpus which was used during the experiments is described in table 2. Sentences were taken from French-Japanese conversation books [8, 9]. The presence of short sentences in the conversation language world reduces the average length of a sentence. The translation examples base is initially empty. Sen- tences are entered pair by pair into the system which predicts the word correspondences between them. Results are corrected manually if necessary, and finally the new pair is inserted in the corpus. a of equation (1) is set to 10, and the equation of the similarity metric becomes: SM = 10* NE NP\t (4) If a is set to high value the similarity metric almost depends on the number of exact matches or NE. The effect of the number of POS tag matches appears only when the numbers of exact matches are almost the same. n is set to 5. In other words, at most 5 segments are selected for each token of the input sentence. Preliminary experiments were carried out to determine these values of c and n. 800 pairs of trans- lation examples were used and 200 new pairs were entered into the system. Different values ranging from 1 to 10 were given to a and to n. The exact prediction rate and the ratio of the number of extracted word correspondences are observed for each situation. According to that result, the greater a is, the more high prediction rate is obtained. As for n, low value n gives higher rates. On the other hand, the variation of a does not affect the ratio of the exctracted word correspondences much. High value n gives higher ratio. The difference seems important between n = 1 and n = 2, hut gets smaller as n increases. a = 10 and n = 5 were the most appropriate for high prediction rates with many extracted word correspondences. Having these parameters determined, 2,600 translation pairs were entered one by one into the system. If the predicted word correspondences are not correct, manual correction is performed. To decide whether -281- With learning process Without learning process 90 0 85 80 75 x 70 65 Without learning process With learning process 90 w x 080 78 t S- t-- a) I g70 0 -0 13 cu L.. Lu\t 60 5\t 9\t 13\t 17\t 21 \t 25 Number of translation examples (x100) Figure 4: Variation of the exact , word correspondence rate by the number of translation examples 40 5\t 9\t 13\t 17\t 21 \t 25 Number of the translation examples (x100) Figure 5: Percentage of the number of extracted word correspondences the result is accurate or not we have created a list of correct word correspondences for each pair. Results are compared to the list and any missing link is considered to be false. Results are divided per 100 pairs. The correct correspondence rate, and the ratio of the number of extracted links were observed. In addition, we had done another experiment in which the learning process was not. performed, and from which the effect of the learning process was verified. The exact correspondence rates and the ratio of the extracted correspondences are respectively presented in figure 4 and figure 5. Next, the number of correspondences which were extracted from exact matches and those which were from POS tag matches were counted. It is summarized in table 3.In figure 4, the accuracy rate increases as the number of translation examples increases. The slope is small but the graph does not decrease. As the number of translation examples goes beyond 1,000, more than 80 of accuracy rates are obtained. The highest value, which is 90.0%, is detected at 2,600 transla- tion examples. The graph surpasses the one of \"without learning process\". It confirms the effectiveness of the learning process in the method. In figure 5, the increase of the number of the extracted links is -282- Table 3: Usefulness of the POS tags Extracted word correspondences Exact word correspondences Exact, word correspondences rate POS Tag Match Exact Match 33.1% 66.9% 26.0% 74.0% 65.2% 91.9% Total or Average 100.0% 100.0% 83.1% (French Sentence) les/DTN heures/SBC d'/PREP ouverture/SBC sont/ECJ de/PREP elle/DTN heure/SBC b./PREP elle/D heure/SBC ?/? eigyou/6 jikan/6 wa/9 nanji/6 kara/9 nanji/6 made/9 desu/4 ka/9 11 (Japanese Sentence) Figure 6: Example of result clearly visible. The graph is lower than the one of \"without learning process\". However, since translation patterns can still be extracted with fewer word correspondences, the accuracy rate is more important than the number of extracted word correspondences. The highest value, which is 87.2%, corresponds to 2,400 translation examples. Despite of the small number of translation examples and the presence of sentences not following grammar rules in the spoken language, good results were earned. The rising trend of both graphs, with high values being manifested, confirms the effectiveness of our method. An example of the result is presented in figure 6 3 . As the link between \"quelle heure\" (what time) and \"nanji\" shows, links involving multiple tokens were successfully predicted. Logically, \"quelle\" (what) corresponds to 5-tan\", and \"heure\" (time) to aji\". However, since \"nanji\" is a single token, links between \"quelle\" and \"nanji\", and again between \"heure\" and were recognized. Predictions of such links becomes successful because similar cases exist in the translation examples. In addition, links between tokens appearing more than once in a same sentence were predicted successfully. As the example of figure 6 shows, \"quelle heure\" and \"nanji\" appear twice in each sentence, but their respective correspondents are estimated accurately. Such cases can be predicted because not a single token at a time, but longer segments were observed. This cannot be carried out with statistical methods which consider single tokens as unit of observation. According to table 3, 33.1% of the extracted word correspondences are from POS tag matches. This means that in spite of the absence of an exact match in the selected similar segments, correspondences were predicted successfully by POS tags. 65.2% of accuracy rates are still far from perfect, but it is very promising. The ratio of the number of extracted links would have dropped from 75-80% to 50-55% if POS tags were not used. That confirms the usefulness of POS tags. The number of POS tags of both languages affects the results of the matching process. if few POS tags are used, long similar segments can be discovered. However, if that number is too small, incorrect, links easily arise, especially with high frequency POS tags. On the other hand, the greater the number of POS tag is, the less a long similar segment can be found. In that case, links between unregistered tokens are hard to discover. That was one reason of failure. In contrast to Japanese language' s 14 POS tag, French language' s 40 POS tags needs some adjustments. During the matching process, tokens, which could not be aligned with any tokens of similar segments, cause failure. If any link cannot be discovered within the selected similar segment, the prediction process cannot be performed. On the other hand, for links involving multiple tokens, the links are accepted if the prediction is done by a single similar segment. However, if other segments must be used, only the links which can be obtained by the first single segment are approved, and the links becomes incomplete. 3 1n english, the sentence means \"From what time to what time are the business hours?\" -283- Enlargement of the translation examples will of course solve these problems. Nevertheless, as an improve- ment of the method, study on covering the whole input sentence with the selected examples, as well as on restoration of splitted links involving multiple tokens, is still a necessity.In this paper, we have described a method for aligning a pair of translation sentences at sub-sentential level and by analogy. Statistical methods cannot produce reliable results when the corpus size is limited. Therefore, they cannot be applied to unexplored languages whose huge parallel corpus is not available. A method which uses a word correspondences-included initial translation examples is proposed. Links between new pairs of translation sentences is predicted according to links between similar examples. By doing so, links involving multiple tokens, as well as links between a token appearing more than once in the same sentence, can be predicted. Besides, introduction of the learning process avoids reiteration of a previously encountered failure. The rising trend of the number of extracted links, by the augmentation of the translation examples was confirmed. The accuracy rate of prediction is also slightly rising. With 2,600 translation examples, more than 80% of the word correspondences are extracted, with a 90% of accuracy rate of prediction. This is considered to be a good result as far as spoken-language sentences are concerned. On the other hand, the effectiveness of the learning process is confirmed by the fact that the graph of the accuracy rate of prediction surpasses the one without learning process. In addition, links involving multiple tokens and respective links of token appearing more than once in a same sentence were predicted successfully. Adjustment of the number of POS tags in both languages, covering the input sentence with the se- lected examples during the matching process, and restoration of splitted links involving multiple tokens is the next direction of this study. Acknowledgement: This work is partially supported by the Grants from the Government subsidy for aiding scientific researches (No. 10680367) of the Ministry of Education of Japan. Thanks to the \"Institut National de la Langue Francise\" for providing the EBTI tagger program for the French language. 9. REFERENCES [1] T. Andriamanankasina, K. Araki, Y. Miyanaga and K. Tochinai: `'Method for Searching the Best-Matching Sentence in Example-Based Machine Translation\", Technical Report of IEICE, Vol. NLC97-10, pp. 15-20, Japan, 1997. [2] T. Andriamanankasina, K. Araki, Y. Miyanaga and K. Tochinai: \"Machine Translation Based on the Relations between Words\", Proc. of Towards Useful Natural Language Procesing Symposium, Japan, 1997. [3] K. Araki, Y. Takahashi, Y. Momouchi, and K. Tochinai : \"Non-Segmented Kana-Kanji Translation Using Inductive Learning\", Transactions of the IEICE, Vol. J97-D-II, No. 4, pp. 391-402, 1996. [4] P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R.L. Mercer: \"The Mathematics of Statistical Machine Translation: Parameter Estimation\", Computational Linguistics, Vol. 19, No. 2, pp. 263- 309, 1993. [5] D. Melamed: \"A Word-to-Word Model of Translational Equivalence\", 35th Conference of the Asso- ciation for Computational Linguistics ACL'97, Spain, 1997. [6] M. Kitamura, and Y. Matsumoto: \"Automatic Extraction of Translation Patterns in Parallel Corpora \", Transactions of the IPSJ, Vol. 38, No. 4, pp. 727-736, 1997. [7] T. Yamashita: \"ChaSen Technical Report\", Nara Advanced Institute of Science and Technology, 1996. [8] S. Meguro: \"Manuel de Conversation Francaise\", Hakusuisha Tokyo, 1987. [9] F. Sato: \"Locutions de base\", Hakusuisha, Tokyo, 1990. -284-", "year": "1999"}]